
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.4.0, mkdocs-material-8.5.6" name="generator"/>
<title>数据倾斜 - 大数据成神之路</title>
<link href="../../../assets/stylesheets/main.20d9efc8.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.cbb835fc.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gdesc-inner { font-size: 0.75rem; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                </style><script src="../../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="" data-md-color-primary="orange" data-md-color-scheme="default" dir="ltr">
<script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#_1">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="大数据成神之路" class="md-header__button md-logo" data-md-component="logo" href="../../.." title="大数据成神之路">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            大数据成神之路
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              数据倾斜
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="orange" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="blue-grey" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
</form>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/maomao199691/Python_Code.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    maomao199691/Python_Code
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="大数据成神之路" class="md-nav__button md-logo" data-md-component="logo" href="../../.." title="大数据成神之路">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    大数据成神之路
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/maomao199691/Python_Code.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    maomao199691/Python_Code
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" id="__nav_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_1">
          Home
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Home" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
          Home
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../..">
        大数据技术之高频面试题
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E8%A7%84%E5%88%92/">
        实时数仓规划
      </a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_3" id="__nav_1_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_1_3">
          项目涉及技术
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="项目涉及技术" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_3">
<span class="md-nav__icon md-icon"></span>
          项目涉及技术
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../Linux%26Shell/">
        Linux&amp;Shell
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../JavaSE/">
        JavaSE
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Hadoop/">
        Hadoop
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Zookeeper/">
        Zookeeper
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Flume/">
        Flume
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Kafka/">
        Kafka
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Hive/">
        Hive
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Datax/">
        Datax
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Maxwell/">
        Maxwell
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../DolphinScheduler/">
        DolphinScheduler
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Scala/">
        Scala
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SparkCore%26SQL/">
        Spark Core&amp;SQL
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SparkStreaming/">
        Spark Streaming
      </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
          数据倾斜
          <span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
        数据倾斜
      </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#_2">
    数据倾斜表现
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3">
    数据倾斜产生原因
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_4">
    解决数据倾斜思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_5">
    定位导致数据倾斜代码
  </a>
<nav aria-label="定位导致数据倾斜代码" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#task">
    某个task执行特别慢的情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#task_1">
    某个task莫名其妙内存溢出的情况
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key">
    查看导致数据倾斜的key分布情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark">
    Spark 数据倾斜的解决方案
  </a>
<nav aria-label="Spark 数据倾斜的解决方案" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#hive-etl">
    使用Hive ETL预处理数据
  </a>
<nav aria-label="使用Hive ETL预处理数据" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_6">
    适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_7">
    实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_8">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_9">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_10">
    方案实践经验
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_11">
    项目实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key_1">
    过滤少数导致倾斜的key
  </a>
<nav aria-label="过滤少数导致倾斜的key" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_12">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_13">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_14">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_15">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_16">
    方案实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shuffle">
    提高shuffle操作的并行度
  </a>
<nav aria-label="提高shuffle操作的并行度" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_17">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_18">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_19">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_20">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_21">
    方案实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_22">
    两阶段聚合（局部聚合+全局聚合）
  </a>
<nav aria-label="两阶段聚合（局部聚合+全局聚合）" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_23">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_24">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_25">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_26">
    方案优缺点
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reduce-joinmap-join">
    将reduce join转为map join
  </a>
<nav aria-label="将reduce join转为map join" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_27">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_28">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_29">
    方案优缺点
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#keyjoin">
    采样倾斜key并分拆join操作
  </a>
<nav aria-label="采样倾斜key并分拆join操作" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_30">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_31">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_32">
    方案优缺点
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rddjoin">
    使用随机前缀和扩容RDD进行join
  </a>
<nav aria-label="使用随机前缀和扩容RDD进行join" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_33">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_34">
    方案实现思路
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Flink/">
        Flink
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Flink%E5%AE%9E%E6%97%B6%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96/">
        Flink实时项目优化
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../HBase/">
        HBase
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../ClickHouse/">
        ClickHouse
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Sqoop/">
        Sqoop
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Azkaban/">
        Azkaban
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/">
        数仓架构
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1/">
        数仓建模
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E4%B8%9A%E5%8A%A1/">
        生产经验—业务
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E6%B5%8B%E8%AF%95%E4%B8%8A%E7%BA%BF%E7%9B%B8%E5%85%B3/">
        生产经验--测试上线相关
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E6%8A%80%E6%9C%AF/">
        生产经验—技术
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E7%83%AD%E7%82%B9%E9%97%AE%E9%A2%98/">
        生产经验—热点问题
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E7%AE%A1%E7%90%86/">
        数据质量
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE/">
        实时数仓项目
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JavaSE/">
        JavaSE
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/Redis/">
        Redis
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/MySql/">
        MySql
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JVM/">
        JVM
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JUC/">
        JUC
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E9%9D%A2%E8%AF%95%E8%AF%B4%E6%98%8E/">
        面试说明
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/LeetCode%E9%A2%98%E7%9B%AE%E7%B2%BE%E9%80%89/">
        LeetCode题目精选
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E6%89%8B%E5%86%99HQL%E9%A2%98%E7%9B%AE%E7%BB%83%E4%B9%A0/">
        手写HQL题目练习
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#_2">
    数据倾斜表现
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3">
    数据倾斜产生原因
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_4">
    解决数据倾斜思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_5">
    定位导致数据倾斜代码
  </a>
<nav aria-label="定位导致数据倾斜代码" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#task">
    某个task执行特别慢的情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#task_1">
    某个task莫名其妙内存溢出的情况
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key">
    查看导致数据倾斜的key分布情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark">
    Spark 数据倾斜的解决方案
  </a>
<nav aria-label="Spark 数据倾斜的解决方案" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#hive-etl">
    使用Hive ETL预处理数据
  </a>
<nav aria-label="使用Hive ETL预处理数据" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_6">
    适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_7">
    实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_8">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_9">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_10">
    方案实践经验
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_11">
    项目实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key_1">
    过滤少数导致倾斜的key
  </a>
<nav aria-label="过滤少数导致倾斜的key" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_12">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_13">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_14">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_15">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_16">
    方案实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shuffle">
    提高shuffle操作的并行度
  </a>
<nav aria-label="提高shuffle操作的并行度" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_17">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_18">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_19">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_20">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_21">
    方案实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_22">
    两阶段聚合（局部聚合+全局聚合）
  </a>
<nav aria-label="两阶段聚合（局部聚合+全局聚合）" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_23">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_24">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_25">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_26">
    方案优缺点
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reduce-joinmap-join">
    将reduce join转为map join
  </a>
<nav aria-label="将reduce join转为map join" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_27">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_28">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_29">
    方案优缺点
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#keyjoin">
    采样倾斜key并分拆join操作
  </a>
<nav aria-label="采样倾斜key并分拆join操作" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_30">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_31">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_32">
    方案优缺点
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rddjoin">
    使用随机前缀和扩容RDD进行join
  </a>
<nav aria-label="使用随机前缀和扩容RDD进行join" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_33">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_34">
    方案实现思路
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/maomao199691/Python_Code.git/edit/master/docs/home/项目涉及技术/数据倾斜.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"></path></svg>
</a>
<h1 id="_1">数据倾斜</h1>
<p>  公司一：总用户量1000万，5台64G内存的服务器。</p>
<p>  公司二：总用户量10亿，1000台64G内存的服务器。</p>
<p>  （1）公司一的数据分析师在做join的时候发生了数据倾斜，会导致有几百万用户的相关数据集中到了一台服务器上，几百万的用户数据，说大也不大，正常字段量的数据的话64G还是能轻松处理掉的。</p>
<p>  （2）公司二的数据分析师在做join的时候也发生了数据倾斜，可能会有1个亿的用户相关数据集中到了一台机器上了（相信我，这很常见）。这时候一台机器就很难搞定了，最后会很难算出结果。</p>
<h2 id="_2">数据倾斜表现</h2>
<p><strong>1）hadoop 中的数据倾斜表现：</strong></p>
<ul>
<li>
<p>有一个多几个Reduce卡住，卡在99.99%，一直不能结束。</p>
</li>
<li>
<p>各种container报错OOM</p>
</li>
<li>
<p>异常的Reducer读写的数据量极大，至少远远超过其它正常的Reducer</p>
</li>
<li>
<p>伴随着数据倾斜，会出现任务被kill等各种诡异的表现。</p>
</li>
</ul>
<p><strong>2）hive 中数据倾斜</strong></p>
<p> 一般都发生在Sql中group by和join on上，而且和数据逻辑绑定比较深。</p>
<p><strong>3）Spark中的数据倾斜</strong></p>
<p> Spark中的数据倾斜，包括Spark Streaming和Spark Sql，表现主要有下面几种：</p>
<ul>
<li>
<p>Executor lost，OOM，Shuffle过程出错；</p>
</li>
<li>
<p>Driver OOM；</p>
</li>
<li>
<p>单个Executor执行时间特别久，整体任务卡在某个阶段不能结束；</p>
</li>
<li>
<p>正常运行的任务突然失败；</p>
</li>
</ul>
<h2 id="_3">数据倾斜产生原因</h2>
<p>  我们以Spark和Hive的使用场景为例。</p>
<p>  他们在做数据运算的时候会涉及到，count distinct、group by、join on等操作，这些都会触发Shuffle动作。一旦触发Shuffle，所有相同key的值就会被拉到一个或几个Reducer节点上，容易发生单点计算问题，导致数据倾斜。</p>
<p>  一般来说，数据倾斜原因有以下几方面：</p>
<p><center><strong>key分布不均匀</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/13/EKi3BCYVdvfwnLe.png"><img alt="trigger" src="https://s2.loli.net/2022/10/13/EKi3BCYVdvfwnLe.png" width="width"/></a></p>
<p><strong>2）建表时考虑不周</strong></p>
<p>  我们举一个例子，就说数据默认值的设计吧，假设我们有两张表：</p>
<p>  user（用户信息表）：userid，register_ip</p>
<p>  ip（IP表）：ip，register_user_cnt</p>
<p>  这可能是两个不同的人开发的数据表。如果我们的数据规范不太完善的话，会出现一种情况：</p>
<p>  user表中的register_ip字段，如果获取不到这个信息，我们默认为null；</p>
<p>  但是在ip表中，我们在统计这个值的时候，为了方便，我们把获取不到ip的用户，统一认为他们的ip为0。</p>
<p>  两边其实都没有错的，但是一旦我们做关联了，这个任务会在做关联的阶段，也就是sql的on的阶段卡死。</p>
<p><strong>3）业务数据激增</strong></p>
<p>  比如订单场景，我们在某一天在北京和上海两个城市多了强力的推广，结果可能是这两个城市的订单量增长了10000%，其余城市的数据量不变。</p>
<p>  然后我们要统计不同城市的订单情况，这样，一做group操作，可能直接就数据倾斜了。</p>
<h2 id="_4">解决数据倾斜思路</h2>
<p>  很多数据倾斜的问题，都可以用和平台无关的方式解决，比如更好的<strong>数据预处理</strong>，<strong>异常值的过滤</strong>等。因此，解决数据倾斜的重点在于对数据设计和业务的理解，这两个搞清楚了，数据倾斜就解决了大部分了。</p>
<p><strong>1）业务逻辑</strong></p>
<p>  我们从业务逻辑的层面上来优化数据倾斜，比如上面的两个城市做推广活动导致那两个城市数据量激增的例子，我们可以单独对这两个城市来做count，单独做时可用两次MR，第一次打散计算，第二次再最终聚合计算。完成后和其它城市做整合。</p>
<p><strong>2）程序层面</strong></p>
<p>  比如说在Hive中，经常遇到count(distinct)操作，这样会导致最终只有一个Reduce任务。</p>
<p>  我们可以先group by，再在外面包一层count，就可以了。比如计算按用户名去重后的总用户量：</p>
<p>  （1）优化前 只有一个reduce，先去重再count负担比较大：</p>
<p>    select name,count(distinct name)from user;</p>
<p>  （2）优化后</p>
<p>    // 设置该任务的每个job的reducer个数为3个。Hive默认-1，自动推断。</p>
<p>    set mapred.reduce.tasks=3;</p>
<p>    // 启动两个job，一个负责子查询(可以有多个reduce)，另一个负责count(1)：</p>
<p>    select count(1) from (select name from user group by name) tmp;</p>
<p><strong>3）调参方面</strong></p>
<p>  Hadoop和Spark都自带了很多的参数和机制来调节数据倾斜，合理利用它们就能解决大部分问题。</p>
<p><strong>4）从业务和数据上解决数据倾斜</strong></p>
<p>  很多数据倾斜都是在数据的使用上造成的。我们举几个场景，并分别给出它们的解决方案。</p>
<ul>
<li>
<p>有损的方法：找到异常数据，比如ip为0的数据，过滤掉</p>
</li>
<li>
<p>无损的方法：对分布不均匀的数据，单独计算</p>
</li>
<li>
<p>先对key做一层hash，先将数据随机打散让它的并行度变大，再汇集</p>
</li>
<li>
<p>数据预处理</p>
</li>
</ul>
<h2 id="_5">定位导致数据倾斜代码</h2>
<p>  Spark数据倾斜只会发生在shuffle过程中。</p>
<p>  这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。</p>
<p>  出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。</p>
<h3 id="task">某个task执行特别慢的情况</h3>
<p>  首先要看的，就是数据倾斜发生在第几个stage中：</p>
<p>  如果是用yarn-client模式提交，那么在提交的机器本地是直接可以看到log，可以在log中找到当前运行到了第几个stage；</p>
<p>  如果是用yarn-cluster模式提交，则可以通过Spark Web UI来查看当前运行到了第几个stage。</p>
<p>  此外，无论是使用yarn-client模式还是yarn-cluster模式，我们都可以在Spark Web UI上深入看一下当前这个stage各个task分配的数据量，从而进一步确定是不是task分配的数据不均匀导致了数据倾斜。</p>
<p>  看task运行时间和数据量</p>
<p>  task运行时间</p>
<p>  比如下图中，倒数第三列显示了每个task的运行时间。明显可以看到，有的task运行特别快，只需要几秒钟就可以运行完；而有的task运行特别慢，需要几分钟才能运行完，此时单从运行时间上看就已经能够确定发生数据倾斜了。</p>
<p>  task数据量</p>
<p>  此外，倒数第一列显示了每个task处理的数据量，明显可以看到，运行时间特别短的task只需要处理几百KB的数据即可，而运行时间特别长的task需要处理几千KB的数据，处理的数据量差了10倍。此时更加能够确定是发生了数据倾斜。</p>
<p>  推断倾斜代码</p>
<p>  知道数据倾斜发生在哪一个stage之后，接着我们就需要根据stage划分原理，推算出来发生倾斜的那个stage对应代码中的哪一部分，这部分代码中肯定会有一个shuffle类算子。</p>
<p>  精准推算stage与代码的对应关系，需要对Spark的源码有深入的理解，这里我们可以介绍一个相对简单实用的推算方法：只要看到Spark代码中出现了一个shuffle类算子或者是Spark SQL的SQL语句中出现了会导致shuffle的语句（比如group by语句），那么就可以判定，以那个地方为界限划分出了前后两个stage。</p>
<p>  这里我们就以如下单词计数来举例。</p>
<p>  val conf = new SparkConf()val sc = new SparkContext(conf)val lines = sc.textFile("hdfs://...")val words = lines.flatMap(<em>.split(" "))val pairs = words.map((</em>, 1))val wordCounts = pairs.reduceByKey(<em> + </em>)wordCounts.collect().foreach(println(_))</p>
<p>  在整个代码中只有一个reduceByKey是会发生shuffle的算子，也就是说这个算子为界限划分出了前后两个stage：</p>
<p>  stage0，主要是执行从textFile到map操作，以及shuffle write操作（对pairs RDD中的数据进行分区操作，每个task处理的数据中，相同的key会写入同一个磁盘文件内）。</p>
<p>  stage1，主要是执行从reduceByKey到collect操作，以及stage1的各个task一开始运行，就会首先执行shuffle read操作（会从stage0的各个task所在节点拉取属于自己处理的那些key，然后对同一个key进行全局性的聚合或join等操作，在这里就是对key的value值进行累加）</p>
<p>  stage1在执行完reduceByKey算子之后，就计算出了最终的wordCounts RDD，然后会执行collect算子，将所有数据拉取到Driver上，供我们遍历和打印输出。</p>
<p>  123456789</p>
<p>  通过对单词计数程序的分析，希望能够让大家了解最基本的stage划分的原理，以及stage划分后shuffle操作是如何在两个stage的边界处执行的。然后我们就知道如何快速定位出发生数据倾斜的stage对应代码的哪一个部分了。</p>
<p>  比如我们在Spark Web UI或者本地log中发现，stage1的某几个task执行得特别慢，判定stage1出现了数据倾斜，那么就可以回到代码中，定位出stage1主要包括了reduceByKey这个shuffle类算子，此时基本就可以确定是是该算子导致了数据倾斜问题。</p>
<p>  此时，如果某个单词出现了100万次，其他单词才出现10次，那么stage1的某个task就要处理100万数据，整个stage的速度就会被这个task拖慢。</p>
<h3 id="task_1">某个task莫名其妙内存溢出的情况</h3>
<p>  这种情况下去定位出问题的代码就比较容易了。我们建议直接看yarn-client模式下本地log的异常栈，或者是通过YARN查看yarn-cluster模式下的log中的异常栈。一般来说，通过异常栈信息就可以定位到你的代码中哪一行发生了内存溢出。然后在那行代码附近找找，一般也会有shuffle类算子，此时很可能就是这个算子导致了数据倾斜。</p>
<p>  但是大家要注意的是，不能单纯靠偶然的内存溢出就判定发生了数据倾斜。因为自己编写的代码的bug，以及偶然出现的数据异常，也可能会导致内存溢出。因此还是要按照上面所讲的方法，通过Spark Web UI查看报错的那个stage的各个task的运行时间以及分配的数据量，才能确定是否是由于数据倾斜才导致了这次内存溢出。</p>
<h2 id="key">查看导致数据倾斜的key分布情况</h2>
<p>  先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印样本数据中各个key的出现次数。</p>
<p>  val sampledPairs = pairs.sample(false, 0.1)</p>
<p>  val sampledWordCounts = sampledPairs.countByKey()</p>
<p>  sampledWordCounts.foreach(println(_))</p>
<h2 id="spark">Spark 数据倾斜的解决方案</h2>
<h3 id="hive-etl">使用Hive ETL预处理数据</h3>
<h4 id="_6">适用场景</h4>
<p>  导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。</p>
<h4 id="_7">实现思路</h4>
<p>  此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。</p>
<h4 id="_8">方案实现原理</h4>
<p>  这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。</p>
<h4 id="_9">方案优缺点</h4>
<p>  优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</p>
<p>  缺点：治标不治本，Hive ETL中还是会发生数据倾斜。</p>
<h4 id="_10">方案实践经验</h4>
<p>  在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</p>
<h4 id="_11">项目实践经验</h4>
<p>  在美团·点评的交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。</p>
<h3 id="key_1">过滤少数导致倾斜的key</h3>
<h4 id="_12">方案适用场景</h4>
<p>  如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</p>
<h4 id="_13">方案实现思路</h4>
<p>  如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。</p>
<p>  比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。</p>
<p>  如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。</p>
<h4 id="_14">方案实现原理</h4>
<p>  将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。</p>
<h4 id="_15">方案优缺点</h4>
<p>  优点：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</p>
<p>  缺点：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。</p>
<h4 id="_16">方案实践经验</h4>
<p>  在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</p>
<h3 id="shuffle">提高shuffle操作的并行度</h3>
<h4 id="_17">方案适用场景</h4>
<p>  如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。</p>
<h4 id="_18">方案实现思路</h4>
<p>  在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，默认是200，对于很多场景来说都有点过小。</p>
<h4 id="_19">方案实现原理</h4>
<p>  增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。</p>
<p>  而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。</p>
<p><center><strong>提高shuffle操作的并行度-方案实现原理</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://i.postimg.cc/fbKBpVwR/shuffle-1.png"><img alt="trigger" src="https://i.postimg.cc/fbKBpVwR/shuffle-1.png" width="width"/></a></p>
<h4 id="_20">方案优缺点</h4>
<p>优点：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。</p>
<p>缺点：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。</p>
<h4 id="_21">方案实践经验</h4>
<p>  该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。</p>
<h3 id="_22">两阶段聚合（局部聚合+全局聚合）</h3>
<h4 id="_23">方案适用场景</h4>
<p>  对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。</p>
<h4 id="_24">方案实现思路</h4>
<p>这个方案的核心实现思路就是进行两阶段聚合：</p>
<p>  第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。</p>
<p>  接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。</p>
<p>  然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p>
<p>示例代码如下：</p>
<pre><code class="language-java">// 第一步，给RDD中的每个key都打上一个随机前缀。
JavaPairRDD&lt;String, Long&gt; randomPrefixRdd = rdd.mapToPair(
        new PairFunction&lt;Tuple2&lt;Long,Long&gt;, String, Long&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2&lt;String, Long&gt; call(Tuple2&lt;Long, Long&gt; tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(10);
                return new Tuple2&lt;String, Long&gt;(prefix + "_" + tuple._1, tuple._2);
            }
        });

// 第二步，对打上随机前缀的key进行局部聚合。
JavaPairRDD&lt;String, Long&gt; localAggrRdd = randomPrefixRdd.reduceByKey(
        new Function2&lt;Long, Long, Long&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });

// 第三步，去除RDD中每个key的随机前缀。
JavaPairRDD&lt;Long, Long&gt; removedRandomPrefixRdd = localAggrRdd.mapToPair(
        new PairFunction&lt;Tuple2&lt;String,Long&gt;, Long, Long&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2&lt;Long, Long&gt; call(Tuple2&lt;String, Long&gt; tuple)
                    throws Exception {
                long originalKey = Long.valueOf(tuple._1.split("_")[1]);
                return new Tuple2&lt;Long, Long&gt;(originalKey, tuple._2);
            }
        });

// 第四步，对去除了随机前缀的RDD进行全局聚合。
JavaPairRDD&lt;Long, Long&gt; globalAggrRdd = removedRandomPrefixRdd.reduceByKey(
        new Function2&lt;Long, Long, Long&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });
</code></pre>
<h4 id="_25">方案实现原理</h4>
<p>  将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。</p>
<p><center><strong>提高shuffle操作的并行度-方案实现原理2</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://i.postimg.cc/ZnTGyGVw/Sparkshuffle-2.png"><img alt="trigger" src="https://i.postimg.cc/ZnTGyGVw/Sparkshuffle-2.png" width="width"/></a></p>
<h4 id="_26">方案优缺点</h4>
<p>优点</p>
<p>  对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</p>
<p>缺点</p>
<p>  仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</p>
<h3 id="reduce-joinmap-join">将reduce join转为map join</h3>
<h4 id="_27">方案适用场景</h4>
<p>  在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。</p>
<h4 id="_28">方案实现思路</h4>
<p>  不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量，广播给其他Executor节点；</p>
<p>  接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</p>
<p>示例如下：</p>
<pre><code class="language-java">// 首先将数据量比较小的RDD的数据，collect到Driver中来。
List&lt;Tuple2&lt;Long, Row&gt;&gt; rdd1Data = rdd1.collect()
// 然后使用Spark的广播功能，将小RDD的数据转换成广播变量，这样每个Executor就只有一份RDD的数据。
// 可以尽可能节省内存空间，并且减少网络传输性能开销。
final Broadcast&lt;List&lt;Tuple2&lt;Long, Row&gt;&gt;&gt; rdd1DataBroadcast = sc.broadcast(rdd1Data);

// 对另外一个RDD执行map类操作，而不再是join类操作。
JavaPairRDD&lt;String, Tuple2&lt;String, Row&gt;&gt; joinedRdd = rdd2.mapToPair(
        new PairFunction&lt;Tuple2&lt;Long,String&gt;, String, Tuple2&lt;String, Row&gt;&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2&lt;String, Tuple2&lt;String, Row&gt;&gt; call(Tuple2&lt;Long, String&gt; tuple)
                    throws Exception {
                // 在算子函数中，通过广播变量，获取到本地Executor中的rdd1数据。
                List&lt;Tuple2&lt;Long, Row&gt;&gt; rdd1Data = rdd1DataBroadcast.value();
                // 可以将rdd1的数据转换为一个Map，便于后面进行join操作。
                Map&lt;Long, Row&gt; rdd1DataMap = new HashMap&lt;Long, Row&gt;();
                for(Tuple2&lt;Long, Row&gt; data : rdd1Data) {
                    rdd1DataMap.put(data._1, data._2);
                }
                // 获取当前RDD数据的key以及value。
                String key = tuple._1;
                String value = tuple._2;
                // 从rdd1数据Map中，根据key获取到可以join到的数据。
                Row rdd1Value = rdd1DataMap.get(key);
                return new Tuple2&lt;String, String&gt;(key, new Tuple2&lt;String, Row&gt;(value, rdd1Value));
            }
        });

// 这里得提示一下。
// 上面的做法，仅仅适用于rdd1中的key没有重复，全部是唯一的场景。
// 如果rdd1中有多个相同的key，那么就得用flatMap类的操作，在进行join的时候不能用map，而是得遍历rdd1所有数据进行join。
// rdd2中每条数据都可能会返回多条join后的数据。
</code></pre>
<p><center><strong>join转为map join-方案实现</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://i.postimg.cc/ZnTGyGVw/Sparkshuffle-2.png"><img alt="trigger" src="https://i.postimg.cc/ZnTGyGVw/Sparkshuffle-2.png" width="width"/></a></p>
<h4 id="_29">方案优缺点</h4>
<p>优点：</p>
<p>  对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</p>
<p>缺点：</p>
<p>  适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</p>
<h3 id="keyjoin">采样倾斜key并分拆join操作</h3>
<h4 id="_30">方案适用场景</h4>
<p>  两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。</p>
<p>  如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。</p>
<h4 id="_31">方案实现思路</h4>
<p>  对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。</p>
<p>  然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀；</p>
<p>  而不会导致倾斜的大部分key形成另外一个RDD。</p>
<p>  接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀；</p>
<p>  不会导致倾斜的大部分key也形成另外一个RDD。</p>
<p>  再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。</p>
<p>  而另外两个普通的RDD就照常join即可。</p>
<p>  最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</p>
<p>示例如下：</p>
<pre><code class="language-java">// 首先从包含了少数几个导致数据倾斜key的rdd1中，采样10%的样本数据。
JavaPairRDD&lt;Long, String&gt; sampledRDD = rdd1.sample(false, 0.1);

// 对样本数据RDD统计出每个key的出现次数，并按出现次数降序排序。
// 对降序排序后的数据，取出top 1或者top 100的数据，也就是key最多的前n个数据。
// 具体取出多少个数据量最多的key，由大家自己决定，我们这里就取1个作为示范。

// 每行数据变为&lt;key,1&gt;
JavaPairRDD&lt;Long, Long&gt; mappedSampledRDD = sampledRDD.mapToPair(
        new PairFunction&lt;Tuple2&lt;Long,String&gt;, Long, Long&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2&lt;Long, Long&gt; call(Tuple2&lt;Long, String&gt; tuple)
                    throws Exception {
                return new Tuple2&lt;Long, Long&gt;(tuple._1, 1L);
            }
        });

// 按key累加行数
JavaPairRDD&lt;Long, Long&gt; countedSampledRDD = mappedSampledRDD.reduceByKey(
        new Function2&lt;Long, Long, Long&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Long call(Long v1, Long v2) throws Exception {
                return v1 + v2;
            }
        });

// 反转key和value,变为&lt;value,key&gt;
JavaPairRDD&lt;Long, Long&gt; reversedSampledRDD = countedSampledRDD.mapToPair(
        new PairFunction&lt;Tuple2&lt;Long,Long&gt;, Long, Long&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2&lt;Long, Long&gt; call(Tuple2&lt;Long, Long&gt; tuple)
                    throws Exception {
                return new Tuple2&lt;Long, Long&gt;(tuple._2, tuple._1);
            }
        });

// 以行数排序key，取最多行数的key
final Long skewedUserid = reversedSampledRDD.sortByKey(false).take(1).get(0)._2;

// 从rdd1中分拆出导致数据倾斜的key，形成独立的RDD。
JavaPairRDD&lt;Long, String&gt; skewedRDD = rdd1.filter(
        new Function&lt;Tuple2&lt;Long,String&gt;, Boolean&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2&lt;Long, String&gt; tuple) throws Exception {
                return tuple._1.equals(skewedUserid);
            }
        });

// 从rdd1中分拆出不导致数据倾斜的普通key，形成独立的RDD。
JavaPairRDD&lt;Long, String&gt; commonRDD = rdd1.filter(
        new Function&lt;Tuple2&lt;Long,String&gt;, Boolean&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2&lt;Long, String&gt; tuple) throws Exception {
                return !tuple._1.equals(skewedUserid);
            }
        });

// rdd2，就是那个所有key的分布相对较为均匀的rdd。
// 这里将rdd2中，前面获取到的key对应的数据，过滤出来，分拆成单独的rdd，并对rdd中的数据使用flatMap算子都扩容100倍。
// 对扩容的每条数据，都打上0～100的前缀。
JavaPairRDD&lt;String, Row&gt; skewedRdd2 = rdd2.filter(
         new Function&lt;Tuple2&lt;Long,Row&gt;, Boolean&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Boolean call(Tuple2&lt;Long, Row&gt; tuple) throws Exception {
                return tuple._1.equals(skewedUserid);
            }
        }).flatMapToPair(new PairFlatMapFunction&lt;Tuple2&lt;Long,Row&gt;, String, Row&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Iterable&lt;Tuple2&lt;String, Row&gt;&gt; call(
                    Tuple2&lt;Long, Row&gt; tuple) throws Exception {
                Random random = new Random();
                List&lt;Tuple2&lt;String, Row&gt;&gt; list = new ArrayList&lt;Tuple2&lt;String, Row&gt;&gt;();
                for(int i = 0; i &lt; 100; i++) {
                    list.add(new Tuple2&lt;String, Row&gt;(i + "_" + tuple._1, tuple._2));
                }
                return list;
            }

        });

// 将rdd1中分拆出来的导致倾斜的key的独立rdd，每条数据都打上100以内的随机前缀。
// 然后将这个rdd1中分拆出来的独立rdd，与上面rdd2中分拆出来的独立rdd，进行join。
JavaPairRDD&lt;Long, Tuple2&lt;String, Row&gt;&gt; joinedRDD1 = skewedRDD.mapToPair(
        new PairFunction&lt;Tuple2&lt;Long,String&gt;, String, String&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2&lt;String, String&gt; call(Tuple2&lt;Long, String&gt; tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(100);
                return new Tuple2&lt;String, String&gt;(prefix + "_" + tuple._1, tuple._2);
            }
        })
        .join(skewedUserid2infoRDD)
        .mapToPair(new PairFunction&lt;Tuple2&lt;String,Tuple2&lt;String,Row&gt;&gt;, Long, Tuple2&lt;String, Row&gt;&gt;() {
                        private static final long serialVersionUID = 1L;
                        @Override
                        public Tuple2&lt;Long, Tuple2&lt;String, Row&gt;&gt; call(
                            Tuple2&lt;String, Tuple2&lt;String, Row&gt;&gt; tuple)
                            throws Exception {
                            long key = Long.valueOf(tuple._1.split("_")[1]);
                            return new Tuple2&lt;Long, Tuple2&lt;String, Row&gt;&gt;(key, tuple._2);
                        }
                    });

// 将rdd1中分拆出来的包含普通key的独立rdd，直接与rdd2进行join。
JavaPairRDD&lt;Long, Tuple2&lt;String, Row&gt;&gt; joinedRDD2 = commonRDD.join(rdd2);

// 将倾斜key join后的结果与普通key join后的结果，uinon起来。
// 就是最终的join结果。
JavaPairRDD&lt;Long, Tuple2&lt;String, Row&gt;&gt; joinedRDD = joinedRDD1.union(joinedRDD2);
</code></pre>
<p><center><strong>采样倾斜key并分拆join操作-方案实现</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://i.postimg.cc/1zmj9k5B/join-map-join.png"><img alt="trigger" src="https://i.postimg.cc/1zmj9k5B/join-map-join.png" width="width"/></a></p>
<h4 id="_32">方案优缺点</h4>
<p>优点：</p>
<p>  对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。</p>
<p>缺点：</p>
<p>  如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</p>
<h3 id="rddjoin">使用随机前缀和扩容RDD进行join</h3>
<h4 id="_33">方案适用场景</h4>
<p>  如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。</p>
<h4 id="_34">方案实现思路</h4>
<p>  该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。</p>
<p>  然后将该RDD的每条数据都打上一个n以内的随机前缀。</p>
<p>  同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。</p>
<p>  最后将两个处理后的RDD进行join即可。</p>
<p>示例代码如下：</p>
<pre><code class="language-java">// 首先将其中一个key分布相对较为均匀的RDD膨胀100倍。
JavaPairRDD&lt;String, Row&gt; expandedRDD = rdd1.flatMapToPair(
        new PairFlatMapFunction&lt;Tuple2&lt;Long,Row&gt;, String, Row&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Iterable&lt;Tuple2&lt;String, Row&gt;&gt; call(Tuple2&lt;Long, Row&gt; tuple)
                    throws Exception {
                List&lt;Tuple2&lt;String, Row&gt;&gt; list = new ArrayList&lt;Tuple2&lt;String, Row&gt;&gt;();
                for(int i = 0; i &lt; 100; i++) {
                    list.add(new Tuple2&lt;String, Row&gt;(0 + "_" + tuple._1, tuple._2));
                }
                return list;
            }
        });

// 其次，将另一个有数据倾斜key的RDD，每条数据都打上100以内的随机前缀。
JavaPairRDD&lt;String, String&gt; mappedRDD = rdd2.mapToPair(
        new PairFunction&lt;Tuple2&lt;Long,String&gt;, String, String&gt;() {
            private static final long serialVersionUID = 1L;
            @Override
            public Tuple2&lt;String, String&gt; call(Tuple2&lt;Long, String&gt; tuple)
                    throws Exception {
                Random random = new Random();
                int prefix = random.nextInt(100);
                return new Tuple2&lt;String, String&gt;(prefix + "_" + tuple._1, tuple._2);
            }
        });

// 将两个处理后的RDD进行join即可。
JavaPairRDD&lt;String, Tuple2&lt;String, Row&gt;&gt; joinedRDD = mappedRDD.join(expandedRDD);
</code></pre>
<p><center><strong>Spark数据倾斜处理小结</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://i.postimg.cc/SKbzC4zL/Spark.png"><img alt="trigger" src="https://i.postimg.cc/SKbzC4zL/Spark.png" width="width"/></a></p>
<script async="" crossorigin="anonymous" data-category="General" data-category-id="DIC_kwDOILD1rs4CR4oA" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="maomao199691/discuss" data-repo-id="R_kgDOILD1rg" data-strict="0" data-theme="light" src="https://giscus.app/client.js">
</script>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: Spark Streaming" class="md-footer__link md-footer__link--prev" href="../SparkStreaming/" rel="prev">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Previous
              </span>
              Spark Streaming
            </div>
</div>
</a>
<a aria-label="Next: Flink" class="md-footer__link md-footer__link--next" href="../Flink/" rel="next">
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Next
              </span>
              Flink
            </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2016 - 2020 Martin Donath
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://twitter.com/squidfunk" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
<script src="../../../assets/javascripts/bundle.078830c0.min.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom"});})</script></body>
</html>