
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.4.0, mkdocs-material-8.5.6" name="generator"/>
<title>ClickHouse - 大数据成神之路</title>
<link href="../../../assets/stylesheets/main.20d9efc8.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.cbb835fc.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gdesc-inner { font-size: 0.75rem; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                </style><script src="../../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="" data-md-color-primary="orange" data-md-color-scheme="default" dir="ltr">
<script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#clickhouse">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="大数据成神之路" class="md-header__button md-logo" data-md-component="logo" href="../../.." title="大数据成神之路">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            大数据成神之路
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              ClickHouse
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="orange" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="blue-grey" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
</form>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/maomao199691/Python_Code.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    maomao199691/Python_Code
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="大数据成神之路" class="md-nav__button md-logo" data-md-component="logo" href="../../.." title="大数据成神之路">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    大数据成神之路
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/maomao199691/Python_Code.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    maomao199691/Python_Code
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" id="__nav_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_1">
          Home
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Home" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
          Home
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../..">
        大数据技术之高频面试题
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E8%A7%84%E5%88%92/">
        实时数仓规划
      </a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_3" id="__nav_1_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_1_3">
          项目涉及技术
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="项目涉及技术" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_3">
<span class="md-nav__icon md-icon"></span>
          项目涉及技术
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../Linux%26Shell/">
        Linux&amp;Shell
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../JavaSE/">
        JavaSE
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Hadoop/">
        Hadoop
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Zookeeper/">
        Zookeeper
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Flume/">
        Flume
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Kafka/">
        Kafka
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Hive/">
        Hive
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Datax/">
        Datax
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Maxwell/">
        Maxwell
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../DolphinScheduler/">
        DolphinScheduler
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Scala/">
        Scala
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SparkCore%26SQL/">
        Spark Core&amp;SQL
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SparkStreaming/">
        Spark Streaming
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Flink/">
        Flink
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../HBase/">
        HBase
      </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<a class="md-nav__link md-nav__link--active" href="./">
        ClickHouse
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Sqoop/">
        Sqoop
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Azkaban/">
        Azkaban
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/">
        数仓架构
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1/">
        数仓建模
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E4%B8%9A%E5%8A%A1/">
        生产经验—业务
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E6%B5%8B%E8%AF%95%E4%B8%8A%E7%BA%BF%E7%9B%B8%E5%85%B3/">
        生产经验—测试上线相关
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E6%8A%80%E6%9C%AF/">
        生产经验—技术
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E7%83%AD%E7%82%B9%E9%97%AE%E9%A2%98/">
        生产经验—热点问题
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE/">
        实时数仓项目
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JavaSE/">
        JavaSE
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/Redis/">
        Redis
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/MySql/">
        MySql
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JVM/">
        JVM
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JUC/">
        JUC
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E9%9D%A2%E8%AF%95%E8%AF%B4%E6%98%8E/">
        面试说明
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/LeetCode%E9%A2%98%E7%9B%AE%E7%B2%BE%E9%80%89/">
        LeetCode题目精选
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E6%89%8B%E5%86%99HQL%E9%A2%98%E7%9B%AE%E7%BB%83%E4%B9%A0/">
        手写HQL题目练习
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/maomao199691/Python_Code.git/edit/master/docs/home/项目涉及技术/ClickHouse.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"></path></svg>
</a>
<h1 id="clickhouse">ClickHouse</h1>
<h1 id="clickhouse_1">第一章 ClickHouse 入门</h1>
<p>  ClickHouse 是俄罗斯的 Yandex 于 2016 年开源的列式存储数据库（DBMS），<font color="red">使用 C++ 语言编写</font>，主要用于在线分析处理查询（OLAP），能够<font color="red">使用 SQL 查询实时生成分析数据报告</font>。</p>
<h2 id="11clickhouse">1.1ClickHouse 的特点</h2>
<h3 id="111">1.1.1 列式存储</h3>
<p>示例：</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>Name</th>
<th>Age</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>张三</td>
<td>18</td>
</tr>
<tr>
<td>2</td>
<td>李四</td>
<td>22</td>
</tr>
<tr>
<td>3</td>
<td>王五</td>
<td>34</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>采用行式存储时，数据在磁盘上的组织结构为：</strong></li>
</ul>
<p><center><strong>行式存储</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/3nYv7UFmVExpMfX.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/3nYv7UFmVExpMfX.png" width="800"/></a></p>
<p>​    优点是想查某个人所有的属性时，可以通过一次磁盘查找加顺序读取就可以。但是想查所有人的年龄时，需要不停的查找，或者全表扫描才行，遍历的很多数据都是不需要的。</p>
<ul>
<li><strong>采用列式存储时，数据在磁盘上的组织结构为：</strong></li>
</ul>
<p><center><strong>列式存储</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/9V8efDatHZmg6qS.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/9V8efDatHZmg6qS.png" width="800"/></a></p>
<ul>
<li>列式存储的好处：</li>
<li>对于列的聚合 ，计数，求和等统计操作原因优于行式存储。</li>
<li>优于某一列的数据类型都是相同的，针对于 数据存储更容易进行数据压缩，每一列选择更优的数据压缩算法，大大提高了数据的压缩比重。</li>
<li>由于数据压缩比更好，一方面节省了磁盘空间，另一方面对于 cache 也有了更大的发挥空间。</li>
</ul>
<h3 id="112-dbms">1.1.2 DBMS 的功能</h3>
<p>  几乎覆盖了标准 SQL 的大部分语法，包括 DDL 和 DML。以及配套的 各种函数，用户管理及权限管理，数据的备份与恢复。</p>
<h3 id="113">1.1.3 多样化引擎</h3>
<p>  ClickHouse 和 MySQL 类似，把表级的存储引擎插件化，根据表的不同需求可以设定不同的存储引擎。目前包括合并树、日志、接口和其他四大类 20 多种引擎。</p>
<h3 id="114">1.1.4 高吞吐写入能力</h3>
<p>  ClickHouse 采用类 LSM Tree的结构，数据写入后定期在后台 Compaction。通过类 LSM Tree 的结构，ClickHouse 在数据导入时全部都是顺序 append 写，写入后数据段不可更改，在后台 compaction 时也是多个段 merger sort 后顺序写回磁盘。顺序写的特性，充分利用了磁盘的吞吐能力，即便在 HDD 上也有着优异的写入性能。</p>
<p>  官方公开benchmark测试显示能够达到50MB-200MB/s的写入吞吐能力，按照每行100Byte估算，大约相当于50W-200W条/s的写入速度。</p>
<h3 id="115">1.1.5 数据分区与线程级并行</h3>
<p>  ClickHouse 将数据划分为多个 partition，每个 partition 再进一步分为多个 index granularity，然后通过多个 CPU 核心分别处理其中的一部分来实现并行数据处理。在这种设计下，单条 Query 就能利用整机所有 CPU。极致的并行处理能力，极大的降低了查询延时。</p>
<p>  所以，ClickHouse 即便对于大量数据的查询也能够化整为零平行处理。但是有一个弊端就是对于单条查询使用多 cpu，就不利于同时并发多条查询。所以对于高 qps 的查询业务，ClickHouse 并不是强项。</p>
<h2 id="12">1.2 性能对比</h2>
<h3 id="121">1.2.1 单表查询</h3>
<p><center><strong>单表查询</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/qJY7yHroUncQ8Bx.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/qJY7yHroUncQ8Bx.png" width="800"/></a></p>
<h3 id="122">1.2.2 关联查询</h3>
<p><center><strong>关联查询</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/72Kdq3DPw6OgRlM.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/72Kdq3DPw6OgRlM.png" width="800"/></a></p>
<h3 id="123">1.2.3 结论</h3>
<p>  ClickHouse 像很多 OLAP 数据库一样，单表查询速度由于关联查询，而且 ClickHouse 的两者差距更为明显。</p>
<h1 id="_1">第三章  数据类型</h1>
<h2 id="31">3.1 整型</h2>
<p>  固定长度的整型，包括有符号整型或无符号整型。</p>
<h3 id="311-2n-12n-1-1">3.1.1有符号整型（-2n-1~2n-1-1）</h3>
<table>
<thead>
<tr>
<th>类型</th>
<th>范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>Int8</td>
<td>[-128:127]</td>
</tr>
<tr>
<td>Int16</td>
<td>[-32768 : 32767]</td>
</tr>
<tr>
<td>Int32</td>
<td>[-2147483648 : 2147483647]</td>
</tr>
<tr>
<td>Int64</td>
<td>[-9223372036854775808 : 9223372036854775807]</td>
</tr>
</tbody>
</table>
<h3 id="312-02n-1">3.1.2 无符号整型（0~2n-1）</h3>
<table>
<thead>
<tr>
<th>类型</th>
<th>范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>UInt8</td>
<td>[0 : 255]</td>
</tr>
<tr>
<td>UInt16</td>
<td>[0 : 65535]</td>
</tr>
<tr>
<td>UInt32</td>
<td>[0 : 4294967295]</td>
</tr>
<tr>
<td>UInt64</td>
<td>[0 : 18446744073709551615]</td>
</tr>
</tbody>
</table>
<h3 id="312">3.1.2 使用场景</h3>
<p>  个数、数量、存储型 id 等</p>
<h2 id="32">3.2浮点型</h2>
<h3 id="321">3.2.1 类型</h3>
<ul>
<li>
<p>Float32-float</p>
</li>
<li>
<p>Float64-double</p>
</li>
</ul>
<p>  建议尽可能以整数形式存储数据。例如，将固定精度的数字转换成整数值，如时间用毫秒为单位表示，因为浮点型进行计算式可能引起四舍五入的误差。</p>
<pre><code class="language-shell">  longmao :) select 1.0 - 0.9;

  SELECT 1. - 0.9

  ┌──────minus(1., 0.9)─┐
  │ 0.09999999999999998 │
  └─────────────────────┘

  1 rows in set. Elapsed: 0.002 sec.
</code></pre>
<h3 id="322">3.2.2 使用场景</h3>
<p>  一般数据值比较小，不涉及大量的统计计算，精度要求不高的时候。</p>
<h2 id="33">3.3 布尔型</h2>
<p>  没有单独的类型来存储布尔值。可以使用 UInt8 类型，取值限制为 0 或 1。</p>
<h2 id="34-decimal">3.4 Decimal 型</h2>
<p>  有符号的浮点数，可在加、减和乘法运算过程中保持精度。对于除法，最低有效数字会被丢弃（不舍入）。</p>
<h3 id="341">3.4.1 类型</h3>
<ul>
<li>
<p>Decimal32(s)，相当于 Decimal(9-s,s)，有效位数为 1 ~ 9</p>
</li>
<li>
<p>Decimal64(s)，相当于 Decimal(18-s,s)，有效位数为 1 ~ 18</p>
</li>
<li>
<p>Decimal128(s)，相当于 Decimal(38-s,s)，有效位数为 1 ~ 38</p>
</li>
</ul>
<p>  s 标识小数位</p>
<h3 id="342">3.4.2 使用场景</h3>
<p>  一般金额字段、汇率、利率等字段为了保证小数点精度，都使用 Decimal 进型存储。</p>
<h2 id="35">3.5 字符串</h2>
<h3 id="351">3.5.1 类型</h3>
<ul>
<li>String   <ul>
<li>字符串可以任意长度的。它可以包含任意的字节集，包含空字节。</li>
</ul>
</li>
<li>FixedString(N)<ul>
<li>固定长度 N 的字符串，N 必须是严格的正自然数。当服务端读取长度小于 N 的字符串时候，通过在 字符串末尾添加空字节来达到 N  字节长度。当服务端读取长度大于 N 的字符串时候，将返回错误消息。</li>
</ul>
</li>
</ul>
<p>  与 String 相比，极少会使用 FixedString，因为使用起来不是很方便。</p>
<h3 id="352">3.5.2 使用场景</h3>
<p>​   名称、文字描述、字符型编码、固定长度的可以保存一些定长的内容，比如一些编码，性别等，但是考虑到一定的变化风险，带来收益不够明显，所以定长字符串使用意义有限。</p>
<h2 id="36">3.6 枚举类型</h2>
<h3 id="361">3.6.1 类型</h3>
<ul>
<li>Enum8 Enum8 用 'String' = Int8 对描述</li>
<li>Enum16 Enum16 用 'String' = Int16 对描述。</li>
</ul>
<h3 id="362">3.6.2 用法演示</h3>
<p><strong>1）创建一个带有一个枚举 Enum8('hello' = 1,'world' = 2) 类型的列</strong></p>
<pre><code class="language-shell">CREATE TABLE t_enum
(
    `x` Enum8('hello' = 1, 'world' = 2)
)
ENGINE = TinyLog
</code></pre>
<p><strong>2）这个 x 列只能存储类型定义中列出的值：'hello'，'world'</strong></p>
<pre><code class="language-shell">hadoop102 :) select * from t_enum;

SELECT *
FROM t_enum

┌─x─────┐
│ hello │
│ world │
│ hello │
└───────┘
</code></pre>
<p><strong>3）如果尝试保存任何其他值，ClickHouse 抛出异常</strong></p>
<pre><code class="language-shell">hadoop102 :) insert into t_enum values('a');

INSERT INTO t_enum VALUES


Exception on client:
Code: 36. DB::Exception: Unknown element 'a' for type Enum8('hello' = 1, 'world' = 2)

Connecting to localhost:9000 as user default.
Connected to ClickHouse server version 20.4.5 revision 54434.
</code></pre>
<p><strong>4）如果需要看到对应的数值，则必须将 eEnum 值转换为整数类型</strong></p>
<pre><code class="language-shell">hadoop102 :) select  cast(x,'Int8')from t_enum;

SELECT cast(x, 'Int8')
FROM t_enum

┌─cast(x, 'Int8')─┐
│               1 │
│               2 │
│               1 │
└─────────────────┘

3 rows in set. Elapsed: 0.007 sec.
</code></pre>
<h3 id="363">3.6.3 使用场景</h3>
<p>  对一些状态、类型的字段算数一种空间优化，也算是一种数据约束。但是实际使用中往往因为一些数据内容的变化增加一定的维护成本，甚至是数据丢失问题。所以谨慎使用。</p>
<h2 id="37">3.7 时间类型</h2>
<ul>
<li>Date</li>
<li>接收 年—月—日 的字符串，比如 '2019-12-16'</li>
<li>Datetime</li>
<li>接受 年—月—日 时：分：秒 的字符串，比如 '2019-12-16 20:50:10'</li>
<li>Datetime64</li>
<li>接受 年—月—日 时：分：秒.亚秒 的字符串，比如 '2019-12-16 20:50:12.66'</li>
</ul>
<h2 id="38">3.8 数组</h2>
<h3 id="381">3.8.1 类型</h3>
<ul>
<li>Array(T)：由 T 类型元素组成的数组。<ul>
<li>T 可以使任意类型，包含数组类型。但不推荐使用多维数组，ClickHouse 对多维数组的支持有限。例如，不能在 MergeTree 表中存储多维数组。</li>
</ul>
</li>
</ul>
<h3 id="382">3.8.2 用法</h3>
<p><strong>1）创建数组方式1，使用 array 函数</strong></p>
<pre><code class="language-shell">hadoop102 :)  select array(1,2) as x ,toTypeName(x);

SELECT
    [1, 2] AS x,
    toTypeName(x)

┌─x─────┬─toTypeName([1, 2])─┐
│ [1,2] │ Array(UInt8)       │
└───────┴────────────────────┘

1 rows in set. Elapsed: 0.002 sec.
</code></pre>
<p><strong>2）创建数组方式2：使用方括号</strong></p>
<pre><code class="language-shell">hadoop102 :) select [1,2] as x,toTypeName(x);

SELECT
    [1, 2] AS x,
    toTypeName(x)

┌─x─────┬─toTypeName([1, 2])─┐
│ [1,2] │ Array(UInt8)       │
└───────┴────────────────────┘

1 rows in set. Elapsed: 0.003 sec.
</code></pre>
<h1 id="_2">第四章 表引擎</h1>
<p>​   表引擎是 ClickHouse 的一大特色。可以说，表引擎决定了如何存储表的数据。包括：</p>
<ul>
<li>数据的存储方式和位置，写到哪里以及从哪里读取数据</li>
<li>支持哪些查询以及如何支持。</li>
<li>并发数据访问。</li>
<li>索引的使用（如果存在）</li>
<li>是否可以执行多线程请求</li>
<li>数据复制参数</li>
<li>表引擎的使用方式就是必须显示在创建表时定义该表使用的引擎，以及引擎使用的相关参数。</li>
<li>特别注意：<font color="red">引擎的名称大小写敏感</font></li>
</ul>
<h2 id="41-tinylog">4.1 TinyLog</h2>
<p>  以列文件的形式保存在磁盘上，不支持索引，没有比你发控制。一般保存少量数据的小表，生产环境上作用有限。可以用于平时练习测试试用。</p>
<pre><code class="language-shell">hadoop102 :) create table t_tinylog (id String ,name String) engine=TinyLog;
</code></pre>
<h2 id="42-memory">4.2 Memory</h2>
<p>  内存引擎，数据以未压缩的原始形式直接保存在内存当中，服务器重启数据就会小时。读写操作不会相互阻塞，不支持索引。简单查询下有非常非常高的性能表现（超过 10G/s）。</p>
<p>  但是一般用到它的地方不多，除了用来测试，就是在需要非常高的性能，同时数据量又不太大（上限大概 1 亿行）的场景。</p>
<h2 id="43-mergetree">4.3 MergeTree</h2>
<p>  ClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎以及该系列（*MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 至于 Mysql。而且基于 MergeTreee，还衍生出很多其他小弟，也是非常有特色的引擎。</p>
<h3 id="431">4.3.1 用法演示</h3>
<p><strong>1）建表语句</strong></p>
<pre><code> create table t_order_mt(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2),
    create_time Datetime 
)engine = MergeTree
 partition by toYYYYMMDD(create_time)
 primary key (id)
 order by (id,sku_id);
</code></pre>
<p><strong>2）插入数据</strong></p>
<pre><code class="language-shell"> insert into t_order_mt values
 (101,'sku_001',1000.00,'2020-06-01 12:00:00'),
 (102,'sku_002',2000.00,'2020-06-01 11:00:00'),
 (101,'sku_004',2500.00,'2020-06-01 12:00:00'),
 (102,'sku_002',2000.00,'2020-06-01 13:00:00'),
 (102,'sku_002',12000.00,'2020-06-01 13:00:00'),
 (102,'sku_002',600.00,'2020-06-01 12:00:00');
</code></pre>
<p><strong>3）查询数据</strong></p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_mt;

SELECT *
FROM t_order_mt

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 101 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │       600.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘

6 rows in set. Elapsed: 0.002 sec.
</code></pre>
<p>  MergeTree 其实还有很多参数（绝大多数用默认值即可），但是三个参数是更加重要的，也涉及了关于 MergeTree 的很多概念。</p>
<h3 id="432-partition-by">4.3.2 partition by 分区（可选）</h3>
<h4 id="4321">4.3.2.1 作用</h4>
<p>  分区的目的主要是降低扫描的范围，优化查询速度，如果没有指定 partition by，只会使用一个分区。</p>
<h4 id="4322">4.3.2.2 分区目录</h4>
<p>  MergeTree 是以列文件 + 索引文件 + 表定义文件组成的，但是如果设定了分区那么这些文件就会保存到不同的分区目录中。</p>
<h4 id="4323">4.3.2.3 并行</h4>
<p>  分区后，面对涉及跨分区的查询统计，ClickHouse 会以分区为单位并行处理。</p>
<h4 id="4324">4.3.2.4 数据写入与分区合并</h4>
<p>  任何一个批次的数据写入都会产生一个临时分区，不会纳入任何一个已有的分区，写入后的某个时刻（大概 10 ~ 15分钟后），ClickHouse 会自动执行合并操作（等不及也可以手动通过 optimize 执行），把临时分区的数据，合并到已有分区中。</p>
<pre><code>optimize table xxxx final;
</code></pre>
<p><strong>1）再次执行上面的插入操作</strong></p>
<pre><code>insert into  t_order_mt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p><strong>2）查看数据并没有纳入任何分区</strong></p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_mt;

SELECT *
FROM t_order_mt

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 101 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │       600.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 102 │ sku_002 │       600.00 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘

12 rows in set. Elapsed: 0.006 sec.
</code></pre>
<p><strong>3）手动 optimize 之后</strong></p>
<pre><code class="language-shell">hadoop102 :) optimize table t_order_mt final;
</code></pre>
<p><strong>4）再次查询</strong></p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_mt;

SELECT *
FROM t_order_mt

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 101 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │       600.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 102 │ sku_002 │       600.00 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘

12 rows in set. Elapsed: 0.009 sec.
</code></pre>
<h3 id="433-primary-key">4.3.3 primary key 主键（可选）</h3>
<p>  ClickHouse 中的主键，和其他数据库不太一样，<font color="red">它只提供了数据的一级索引，但是却不是唯一约束。这就意味着是可以存在相同 primary key 的数据的。</font></p>
<p>  主键的设定主要依据是查询语句中的 where 条件。根据条件通过对主键进行某种形式的二分查找，能够定位到对应的 index granularity，避免了全表扫描。</p>
<p>  index granularity：直接翻译的话就是索引粒度，指在稀疏索引中两个相邻索引对应数据的间隔。ClickHouse 中的 MergeTree 默认是 8192。官方不建议修改这个值，除非该列存在大量重复值，比如在一个分区中几万行采用一个不同数据。</p>
<p><center><strong>稀疏索引</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/SVjIMyq9YFmUA8W.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/SVjIMyq9YFmUA8W.png" width="800"/></a></p>
<p>  稀疏索引的好处是可以用很少的索引数据，定位更多的数据，代价就是只能定位到索引粒度的第一行，然后再进行一点扫描。</p>
<h3 id="434-order-by">4.3.4 order by（必选）</h3>
<p>  order by 设定了<font color="red">分区内</font>的数据按照哪些字段顺序进行有序保存。</p>
<p>  order by 是 MergeTree 中唯一一个必填项，甚至比 primary key 还重要，因为当用户不设置主键的情况，很多处理会依照 order by 的字段进行处理（比如去重和汇总）</p>
<p>  要求：主键必须是 order by 字段的前缀字段。</p>
<p>  比如 order by 字段是（id,sku_id） 那么主键必须是 id 或者(id,sku_id)</p>
<h2 id="44">4.4 二级索引</h2>
<p>  目前在 ClickHouse 的官网上二级索引的功能是被标注为<font color="red">实验性</font>的。</p>
<h3 id="441">4.4.1 使用演示</h3>
<p><strong>1）使用二级索引前需要增加设置是够允许使用实验性的二级索引</strong></p>
<pre><code class="language-shell">set allow_experimental_data_skipping_indices=1;
</code></pre>
<p><strong>2）创建测试表</strong></p>
<pre><code class="language-shell">create table t_order_mt2(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2),
    create_time Datetime,
    INDEX a total_amount TYPE minmax GRANULARITY 5
)engine =MergeTree
 partition by toYYYYMMDD(create_time)
 primary key (id)
 order by (id,sku_id);
</code></pre>
<p>  其中 GRANULARITYN 是设定二级索引对于一级索引粒度的粒度。</p>
<p><strong>3）插入数据</strong></p>
<pre><code class="language-shell">insert into  t_order_mt2 values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p><strong>4）对比效果</strong></p>
<p>  在使用下面语句进行测试，可以看出二级所用能够为非主键字段的查询发挥作用。</p>
<pre><code class="language-shell">[atguigu@hadoop102 ~]$ clickhouse-client  --send_logs_level=trace &lt;&lt;&lt; 'select * from t_order_mt2  where total_amount &gt; toDecimal32(900., 2)';


[hadoop102] 2022.08.09 20:17:56.647671 [ 4121 ] {c0cbe30f-0d74-4aae-bc24-953dd534d51a} &lt;Debug&gt; default.t_order_mt2 (SelectExecutor): Index `a` has dropped 0 granules.
[hadoop102] 2022.08.09 20:17:56.647742 [ 4121 ] {c0cbe30f-0d74-4aae-bc24-953dd534d51a} &lt;Debug&gt; default.t_order_mt2 (SelectExecutor): Index `a` has dropped 1 granules.
</code></pre>
<h2 id="45-ttl">4.5 数据TTL</h2>
<p>  TTL 即 Time To Live，MergeTree 提供了可以管理数据或者列的生命周期的功能。</p>
<h3 id="451-ttl">4.5.1 列级TTL</h3>
<p><strong>1）创建测试表</strong></p>
<pre><code class="language-shell">create table t_order_mt3(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2)  TTL create_time+interval 10 SECOND,
    create_time  Datetime 
 ) engine =MergeTree
 partition by toYYYYMMDD(create_time)
   primary key (id)
   order by (id, sku_id);
</code></pre>
<p><strong>2）插入数据（注意：根据实际时间改变）</strong></p>
<pre><code class="language-shell">insert into  t_order_mt3 values
(106,'sku_001',1000.00,'2020-06-12 22:52:30'),
(107,'sku_002',2000.00,'2020-06-12 22:52:30'),
(110,'sku_003',600.00,'2020-06-12 22:52:30');
</code></pre>
<p><strong>3）手动合并，查看效果，到期后，指定的字段数据归 0</strong></p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_mt3 ;

SELECT *
FROM t_order_mt3

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 107 │ sku_002 │         0.00 │ 2020-06-12 22:52:30 │
│ 110 │ sku_003 │         0.00 │ 2020-06-12 22:52:30 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 106 │ sku_001 │         0.00 │ 2020-06-12 22:52:30 │
└─────┴─────────┴──────────────┴─────────────────────┘

3 rows in set. Elapsed: 0.008 sec.
</code></pre>
<h3 id="452-ttl">4.5.2 表级 TTL</h3>
<p>  数据会在 create_time 之后 10 秒丢失</p>
<p><strong>1）创建表指定</strong></p>
<pre><code class="language-shell">create table t_order_mt4(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2)  TTL create_time+interval 10 SECOND,
    create_time  Datetime 
 ) engine =MergeTree
 partition by toYYYYMMDD(create_time)
   primary key (id)
   order by (id, sku_id)
   TTL create_time + INTERVAL 10 SECOND;
</code></pre>
<p><strong>2）修改已有的表</strong></p>
<pre><code>alter table t_order_mt3 MODIFY TTL create_time + INTERVAL 10 SECOND;
</code></pre>
<p><strong>3）时间周期</strong></p>
<p>  能够使用的时间周期</p>
<ul>
<li>SECOND</li>
<li>MINUTE</li>
<li>HOUR</li>
<li>DAY</li>
<li>WEEK</li>
<li>MONTH</li>
<li>QUARTER</li>
<li>YEAR</li>
</ul>
<h2 id="46-replacingmergetree">4.6 ReplacingMergeTree</h2>
<p>  ReplacingMergeTree 是 MergeTree 的一个变种，它存储特性完全继承 MergeTree，只是多了一个去重的功能。尽管 MergeTree 可以设置主键，但是 primary key 其实没有唯一约束的功能。如果你想处理掉重复的数据，可以借助这个 ReplacingMergeTree。</p>
<h3 id="461">4.6.1 去重时机</h3>
<p>  数据的去重只会在合并的过程中出现。合并会在未知的时间在后台进行，所以你无法预先作出计划。有一些数据可能仍未被处理。</p>
<h3 id="462">4.6.2 去重范围</h3>
<p>  如果表经过了分区，去重只会在分区内部进行去重，不能执行跨分区的去重。</p>
<p>  所以 ReplacingMergeTree 能力有限，ReplacingMergeTree 适用于在后台清除重复的数据以节省空间，但是它不保证没有重复的数据出现。</p>
<h3 id="463">4.6.3 用法演示</h3>
<p><strong>1）创建表</strong></p>
<pre><code class="language-shell">create table t_order_rmt(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2),
    create_time Datetime
)engine = ReplacingMergeTree(create_time)
 partition by toYYYYMMDD(create_time)
 primary key(id)
 order by (id,sku_id);
</code></pre>
<p>​   <font color="red">ReplacingMergeTree() 填入的参数为版本字段，重复数据保留版本字段值最大的。如果不填版本字段，默认按照插入顺序保留最后一条。</font></p>
<p><strong>2）向表中插入数据</strong></p>
<pre><code class="language-shell">insert into  t_order_rmt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p><strong>3）执行第一次查询</strong></p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_rmt;

SELECT *
FROM t_order_rmt

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 102 │ sku_002 │       600.00 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘

6 rows in set. Elapsed: 0.004 sec.
</code></pre>
<p><strong>4）手动合并</strong></p>
<pre><code class="language-SHELL">OPTIMIZE TABLE t_order_rmt FINAL;
</code></pre>
<p><strong>5）再次执行查询</strong></p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_rmt;

SELECT *
FROM t_order_rmt

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 102 │ sku_002 │       600.00 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘

4 rows in set. Elapsed: 0.008 sec.
</code></pre>
<p><strong>6）结论</strong></p>
<ul>
<li>实际上是使用 order by 字段作为唯一键</li>
<li>去重不能跨分区</li>
<li>只有合并分区才会进行去重</li>
<li>认定重复的数据保留，版本字段值最大的</li>
<li>如果版本字段相同则按插入顺序保留最后一笔</li>
</ul>
<h2 id="47-summingmergetree">4.7 SummingMergeTree</h2>
<p>  对于不查询明细，只关心以维度进行汇总聚合结果的场景。如果只使用普通的 MergeTree 的话，无论是存储空间的开销，还是查询时临时聚合的开销都比较大。</p>
<p>  ClickHouse 为了这种场景，提供了一中能够“预聚合”的引擎 SummingMergeTree</p>
<h3 id="471">4.7.1用法</h3>
<p><strong>1）创建表</strong></p>
<pre><code class="language-shell">create table t_order_smt(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2) ,
    create_time  Datetime 
 ) engine =SummingMergeTree(total_amount)
   partition by toYYYYMMDD(create_time)
   primary key (id)
   order by (id,sku_id );
</code></pre>
<p><strong>2）插入数据</strong></p>
<pre><code class="language-shell">insert into  t_order_smt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p>3）执行第一次查询</p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_smt;

SELECT *
FROM t_order_smt

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 102 │ sku_002 │       600.00 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_002 │      2000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_002 │     12000.00 │ 2020-06-01 13:00:00 │
│ 102 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘

6 rows in set. Elapsed: 0.004 sec.
</code></pre>
<p><strong>4）手动合并</strong></p>
<pre><code>OPTIMIZE TABLE t_order_smt FINAL;
</code></pre>
<p>5）再次执行</p>
<pre><code class="language-shell">hadoop102 :) select * from t_order_smt;

SELECT *
FROM t_order_smt

┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 101 │ sku_001 │      1000.00 │ 2020-06-01 12:00:00 │
│ 102 │ sku_002 │     16000.00 │ 2020-06-01 11:00:00 │
│ 102 │ sku_004 │      2500.00 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 102 │ sku_002 │       600.00 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘

4 rows in set. Elapsed: 0.004 sec.
</code></pre>
<p><strong>6）结论</strong></p>
<ul>
<li>以 SummingMergeTree() 中指定的列作为汇总数据列</li>
<li>可以填写多列必须为数字列，如果不填，以所有非维度列且为数字列的字段为汇总数据列</li>
<li>以 order by 的列为准，作为维度列</li>
<li>其他的列按插入顺序保留第一行</li>
<li>不在一个分区的数据不会被聚合</li>
</ul>
<p><strong>7）开发建议</strong></p>
<p>  设计聚合表的话，唯一键值、流水号可以去掉，所有字段全部是维度、度量或者时间戳。</p>
<p><strong>8）问题</strong></p>
<p>  能不能直接执行以下 SQL 得到汇总值</p>
<pre><code class="language-shell">select total_amount from  XXX where province_name=’’ and create_date=’xxx’
</code></pre>
<p>  不行，可能会包含一些还没来得及聚合的临时明细</p>
<p>  如果要是获取汇总值，还是需要使用sum进行聚合，这样效率会有一定的提高，但本身ClickHouse是列式存储的，效率提升有限，不会特别明显。</p>
<pre><code>select sum(total_amount) from province_name=’’ and create_date=’xxx’
</code></pre>
<h1 id="sql">第五章 SQL 操作</h1>
<p>  基本上来说传统关系型数据库（以MySQL 为例）的 sQL 语句，ClickHouse 基本都支持。</p>
<h2 id="51-insert">5.1 Insert</h2>
<p>1）标准 Insert</p>
<pre><code>insert into [table_name] values(...),(...)
</code></pre>
<p>2）从表到表的 Insert</p>
<pre><code class="language-shell">insert into [table_name] select a,b,c from [table_name_2]
</code></pre>
<h2 id="52-update-delete">5.2 Update 和 Delete</h2>
<p>  ClickHouse 提供了 Delete 和 Update 的能力，这类操作被称为 Mutation(突变)查询，它可以看做 Alter 的一种。</p>
<p>  虽然可以实现修改和删除，但是和一般的 OLTP 数据不一样，<font color="red">Mutation 语句是一种很 “重”的操作，而且不支持事务。</font></p>
<p>  “重”的原因主要是每次修改或者删除都会导致放弃目标数据的原有分区，重建新分区。所以尽量做批量的变更，不要进行频繁小数据的操作。</p>
<p><strong>1）删除操作</strong></p>
<pre><code>alter table t_order_smt delete where sku_id = 'sku_001';
</code></pre>
<p><strong>2）修改操作</strong></p>
<pre><code>alter table t_order_smt update total_amount=toDecimal32(2000.00,2) where id=102;
</code></pre>
<p>  由于操作比较“重”，所以 Mutation 语句分两步执行，同步执行的部分其实只是进行新增数据新增分区和把九分区打上逻辑上的失效标记。直到触发分区合并的时候，才会删除旧数据释放磁盘空间，一般不会开放这样的功能给用户，由管理员完成。</p>
<h2 id="53">5.3 查询操作</h2>
<p>  ClickHouse 基本上与标准 SLQ 差别不大</p>
<ul>
<li>支持子查询</li>
<li>支持 CTE（Common Table Expression 公用表表达式 with 子句）</li>
<li>支持各种 JOIN，但是 JOIN 操作无法使用缓存，所以即使是两次相同的 JOIN 语句，ClickHouse 也会视为两条新的 SQL。</li>
<li>不支持窗口函数</li>
<li>不支持自定义函数</li>
<li>GROUP BY 操作增加了 with rollup\with cube\with total 用来计算小计和总计</li>
</ul>
<p><strong>1）插入数据</strong></p>
<pre><code class="language-shell">hadoop102 :) alter table t_order_mt delete where 1=1;
insert into  t_order_mt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 12:00:00'),
(103,'sku_004',2500.00,'2020-06-01 12:00:00'),
(104,'sku_002',2000.00,'2020-06-01 12:00:00'),
(105,'sku_003',600.00,'2020-06-02 12:00:00'),
(106,'sku_001',1000.00,'2020-06-04 12:00:00'),
(107,'sku_002',2000.00,'2020-06-04 12:00:00'),
(108,'sku_004',2500.00,'2020-06-04 12:00:00'),
(109,'sku_002',2000.00,'2020-06-04 12:00:00'),
(110,'sku_003',600.00,'2020-06-01 12:00:00');
</code></pre>
<p><strong>2）with rollup：从右至左去掉维度进行小计</strong></p>
<pre><code class="language-shell">hadoop102 :) select id,sku_id,sum(total_amount) from t_order_mt group by id,sku_id with rollup;

SELECT
    id,
    sku_id,
    sum(total_amount)
FROM t_order_mt
GROUP BY
    id,
    sku_id
    WITH ROLLUP

┌──id─┬─sku_id──┬─sum(total_amount)─┐
│ 110 │ sku_003 │            600.00 │
│ 109 │ sku_002 │           2000.00 │
│ 107 │ sku_002 │           2000.00 │
│ 106 │ sku_001 │           1000.00 │
│ 102 │ sku_002 │           2000.00 │
│ 104 │ sku_002 │           2000.00 │
│ 103 │ sku_004 │           2500.00 │
│ 108 │ sku_004 │           2500.00 │
│ 105 │ sku_003 │            600.00 │
│ 101 │ sku_001 │           1000.00 │
└─────┴─────────┴───────────────────┘
┌──id─┬─sku_id─┬─sum(total_amount)─┐
│ 110 │        │            600.00 │
│ 106 │        │           1000.00 │
│ 102 │        │           2000.00 │
│ 105 │        │            600.00 │
│ 109 │        │           2000.00 │
│ 107 │        │           2000.00 │
│ 104 │        │           2000.00 │
│ 103 │        │           2500.00 │
│ 108 │        │           2500.00 │
│ 101 │        │           1000.00 │
└─────┴────────┴───────────────────┘
┌─id─┬─sku_id─┬─sum(total_amount)─┐
│  0 │        │          16200.00 │
└────┴────────┴───────────────────┘

21 rows in set. Elapsed: 0.006 sec.
</code></pre>
<p><strong>3）with cube：从右至左去掉维度进行小计，再从左至右去掉维度进行小计</strong></p>
<pre><code class="language-shell">hadoop102 :) select id,sku_id,sum(total_amount) from t_order_mt group by id,sku_id with cube;

SELECT
    id,
    sku_id,
    sum(total_amount)
FROM t_order_mt
GROUP BY
    id,
    sku_id
    WITH CUBE

┌──id─┬─sku_id──┬─sum(total_amount)─┐
│ 110 │ sku_003 │            600.00 │
│ 109 │ sku_002 │           2000.00 │
│ 107 │ sku_002 │           2000.00 │
│ 106 │ sku_001 │           1000.00 │
│ 102 │ sku_002 │           2000.00 │
│ 104 │ sku_002 │           2000.00 │
│ 103 │ sku_004 │           2500.00 │
│ 108 │ sku_004 │           2500.00 │
│ 105 │ sku_003 │            600.00 │
│ 101 │ sku_001 │           1000.00 │
└─────┴─────────┴───────────────────┘
┌──id─┬─sku_id─┬─sum(total_amount)─┐
│ 110 │        │            600.00 │
│ 106 │        │           1000.00 │
│ 102 │        │           2000.00 │
│ 105 │        │            600.00 │
│ 109 │        │           2000.00 │
│ 107 │        │           2000.00 │
│ 104 │        │           2000.00 │
│ 103 │        │           2500.00 │
│ 108 │        │           2500.00 │
│ 101 │        │           1000.00 │
└─────┴────────┴───────────────────┘
┌─id─┬─sku_id──┬─sum(total_amount)─┐
│  0 │ sku_003 │           1200.00 │
│  0 │ sku_004 │           5000.00 │
│  0 │ sku_001 │           2000.00 │
│  0 │ sku_002 │           8000.00 │
└────┴─────────┴───────────────────┘
┌─id─┬─sku_id─┬─sum(total_amount)─┐
│  0 │        │          16200.00 │
└────┴────────┴───────────────────┘

25 rows in set. Elapsed: 0.003 sec.
</code></pre>
<p><strong>4）with totals：只计算合计</strong></p>
<pre><code class="language-shell">hadoop102 :) select id,sku_id,sum(total_amount) from t_order_mt group by id,sku_id with totals;

SELECT
    id,
    sku_id,
    sum(total_amount)
FROM t_order_mt
GROUP BY
    id,
    sku_id
    WITH TOTALS

┌──id─┬─sku_id──┬─sum(total_amount)─┐
│ 110 │ sku_003 │            600.00 │
│ 109 │ sku_002 │           2000.00 │
│ 107 │ sku_002 │           2000.00 │
│ 106 │ sku_001 │           1000.00 │
│ 102 │ sku_002 │           2000.00 │
│ 104 │ sku_002 │           2000.00 │
│ 103 │ sku_004 │           2500.00 │
│ 108 │ sku_004 │           2500.00 │
│ 105 │ sku_003 │            600.00 │
│ 101 │ sku_001 │           1000.00 │
└─────┴─────────┴───────────────────┘

Totals:
┌─id─┬─sku_id─┬─sum(total_amount)─┐
│  0 │        │          16200.00 │
└────┴────────┴───────────────────┘

10 rows in set. Elapsed: 0.003 sec.
</code></pre>
<h2 id="54-alter">5.4 alter 操作</h2>
<p><strong>1）新增字段</strong></p>
<pre><code class="language-shell">alter table tableName  add column  newcolname  String after col1;
</code></pre>
<p><strong>2）修改字段类型</strong></p>
<pre><code>alter table tableName modify column newcolname String;
</code></pre>
<p><strong>3）删除字段</strong></p>
<pre><code>alter table tableName drop column newcolname;
</code></pre>
<h1 id="_3">第六章 副本</h1>
<p>  副本的目的主要是保障数据的高可用型，即使一台 ClickHouse 节点宕机，那么也可以从其他服务器获得相同的数据。</p>
<h2 id="61">6.1 副本写入流程</h2>
<p><center><strong>副本写入流程</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/2BoCaDOyVdIv8Yi.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/2BoCaDOyVdIv8Yi.png" width="800"/></a></p>
<h2 id="_4"></h2>
<h1 id="_5">第七章 分片集群</h1>
<p>  副本虽然能够提高数据的可用性，降低丢失风险，但是每台服务器实际上必须容纳全量数据，对数据的横向扩容没有解决。</p>
<p>  要解决数据水平切分的问题，需要引入分片的概念。通过分片把一份完整的数据进行切分，不同的分片分布到不同的节点上，再通过 Distributed 表引擎把数据拼接起来一同使用。</p>
<p>  Distributed 表引擎本身不存储数据，有点类似于 MyCat 之MySql，成为一种中间件，通过分布式逻辑表来写入、分发、路由来操作多台节点不同分片的分布式数据。</p>
<p>​   <font color="red">注意：ClickHouse 的集群是表级别的，实际企业中，大部分做了高可用，但是没有用分片，避免降低查询性能以及操作集群的复杂性。</font></p>
<h2 id="71-3-2-6">7.1 集群写入流程（3 分片 2 副本 共6个节点）</h2>
<p><center><strong>集群写入流程</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/s2QXGiChF4W1o5U.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/s2QXGiChF4W1o5U.png" width="800"/></a></p>
<h2 id="72-3-2-6">7.2 集群读取流程（3分片 2 副本 共6节点）</h2>
<p><center><strong>集群读取流程</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/rigbtSTHVQmDcuh.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/rigbtSTHVQmDcuh.png" width="800"/></a></p>
<h2 id="73-2-6">7.3 分片 2 副本共6个节点集群配置</h2>
<p>1）<strong>在</strong> <strong>/etc/clickhouse-server/config.d/metrika.xml</strong><strong>文件中配置</strong></p>
<p>  配置的位置还是在之前的/etc/clickhouse-server/config.d/metrika.xml，内容如下</p>
<pre><code>&lt;yandex&gt;
    &lt;clickhouse_remote_servers&gt;
        &lt;gmall_cluster&gt; &lt;!-- 集群名称--&gt; 
            &lt;shard&gt;  &lt;!--集群的第一个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;!--该分片的第一个副本--&gt;
                &lt;replica&gt;    
                    &lt;host&gt;hadoop201&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                 &lt;/replica&gt;
                 &lt;!--该分片的第二个副本--&gt;
                 &lt;replica&gt; 
                    &lt;host&gt;hadoop102&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                 &lt;/replica&gt;
            &lt;/shard&gt;

              &lt;shard&gt;  &lt;!--集群的第二个分片--&gt;
                 &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                 &lt;replica&gt;    &lt;!--该分片的第一个副本--&gt;
                    &lt;host&gt;hadoop103&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                 &lt;/replica&gt;
                 &lt;replica&gt;    &lt;!--该分片的第二个副本--&gt;
                    &lt;host&gt;hadoop104&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                 &lt;/replica&gt;
              &lt;/shard&gt;

              &lt;shard&gt;  &lt;!--集群的第三个分片--&gt;
                 &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                 &lt;replica&gt;     &lt;!--该分片的第一个副本--&gt;
                    &lt;host&gt;hadoop205&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                 &lt;/replica&gt;
                 &lt;replica&gt;    &lt;!--该分片的第二个副本--&gt;
                    &lt;host&gt;hadoop206&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                 &lt;/replica&gt;
              &lt;/shard&gt;
        &lt;/gmall_cluster&gt;
    &lt;/clickhouse_remote_servers&gt;
&lt;/yandex&gt;
</code></pre>
<h2 id="74">7.4 配置三节点版本集群及副本</h2>
<h3 id="741-2">7.4.1 集群及副本规划（2个分片，只有第一个分片有副本）</h3>
<p><center><strong>三节点版本配置</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/4qxM3T1YPvZ8JEA.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/4qxM3T1YPvZ8JEA.png" width="800"/></a></p>
<p><center><strong>配置</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/11/crwosbvA23EZtzU.png"><img alt="trigger" src="https://s2.loli.net/2022/10/11/crwosbvA23EZtzU.png" width="800"/></a></p>
<script async="" crossorigin="anonymous" data-category="General" data-category-id="DIC_kwDOILD1rs4CR4oA" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="maomao199691/discuss" data-repo-id="R_kgDOILD1rg" data-strict="0" data-theme="light" src="https://giscus.app/client.js">
</script>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: HBase" class="md-footer__link md-footer__link--prev" href="../HBase/" rel="prev">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Previous
              </span>
              HBase
            </div>
</div>
</a>
<a aria-label="Next: Sqoop" class="md-footer__link md-footer__link--next" href="../Sqoop/" rel="next">
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Next
              </span>
              Sqoop
            </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2016 - 2020 Martin Donath
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://twitter.com/squidfunk" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
<script src="../../../assets/javascripts/bundle.078830c0.min.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom"});})</script></body>
</html>