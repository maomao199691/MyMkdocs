
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.4.0, mkdocs-material-8.5.6" name="generator"/>
<title>Spark Streaming - 大数据成神之路</title>
<link href="../../../assets/stylesheets/main.20d9efc8.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.cbb835fc.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gdesc-inner { font-size: 0.75rem; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                </style><script src="../../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="" data-md-color-primary="orange" data-md-color-scheme="default" dir="ltr">
<script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#spark-streaming">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="大数据成神之路" class="md-header__button md-logo" data-md-component="logo" href="../../.." title="大数据成神之路">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            大数据成神之路
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Spark Streaming
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="orange" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="blue-grey" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
</form>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/maomao199691/Python_Code.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    maomao199691/Python_Code
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="大数据成神之路" class="md-nav__button md-logo" data-md-component="logo" href="../../.." title="大数据成神之路">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    大数据成神之路
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/maomao199691/Python_Code.git" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    maomao199691/Python_Code
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" id="__nav_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_1">
          Home
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Home" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
          Home
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../..">
        大数据技术之高频面试题
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E8%A7%84%E5%88%92/">
        实时数仓规划
      </a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_3" id="__nav_1_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_1_3">
          项目涉及技术
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="项目涉及技术" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_3">
<span class="md-nav__icon md-icon"></span>
          项目涉及技术
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../Linux%26Shell/">
        Linux&amp;Shell
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../JavaSE/">
        JavaSE
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Hadoop/">
        Hadoop
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Zookeeper/">
        Zookeeper
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Flume/">
        Flume
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Kafka/">
        Kafka
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Hive/">
        Hive
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Datax/">
        Datax
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Maxwell/">
        Maxwell
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../DolphinScheduler/">
        DolphinScheduler
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Scala/">
        Scala
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SparkCore%26SQL/">
        Spark Core&amp;SQL
      </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
          Spark Streaming
          <span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
        Spark Streaming
      </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_1">
    Spark Streaming第一次运行不丢失数据
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_2">
    Spark Streaming精准一次消费
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_3">
    Spark Streaming控制每秒消费数据的速度
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_4">
    Spark Streaming背压机制
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streamingstage">
    Spark Streaming一个stage耗时
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_5">
    Spark Streaming优雅关闭
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_6">
    Spark Streaming默认分区个数
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sparkstreamingkafka">
    SparkStreaming有哪几种方式消费Kafka中的数据，它们之间的区别是什么？
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sparkstreaming">
    简述SparkStreaming窗口函数的原理（重点）
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_1">
    数据倾斜
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2">
    数据倾斜表现
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3">
    数据倾斜产生原因
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_4">
    解决数据倾斜思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_5">
    定位导致数据倾斜代码
  </a>
<nav aria-label="定位导致数据倾斜代码" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#task">
    某个task执行特别慢的情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#task_1">
    某个task莫名其妙内存溢出的情况
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key">
    查看导致数据倾斜的key分布情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark">
    Spark 数据倾斜的解决方案
  </a>
<nav aria-label="Spark 数据倾斜的解决方案" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#hive-etl">
    使用Hive ETL预处理数据
  </a>
<nav aria-label="使用Hive ETL预处理数据" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_6">
    适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_7">
    实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_8">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_9">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_10">
    方案实践经验
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_11">
    项目实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key_1">
    过滤少数导致倾斜的key
  </a>
<nav aria-label="过滤少数导致倾斜的key" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_12">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_13">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_14">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_15">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_16">
    方案实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shuffle">
    提高shuffle操作的并行度
  </a>
<nav aria-label="提高shuffle操作的并行度" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_17">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_18">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_19">
    方案实现原理
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Flink/">
        Flink
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../HBase/">
        HBase
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../ClickHouse/">
        ClickHouse
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Sqoop/">
        Sqoop
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Azkaban/">
        Azkaban
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/">
        数仓架构
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1/">
        数仓建模
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E4%B8%9A%E5%8A%A1/">
        生产经验—业务
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E6%B5%8B%E8%AF%95%E4%B8%8A%E7%BA%BF%E7%9B%B8%E5%85%B3/">
        生产经验—测试上线相关
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E6%8A%80%E6%9C%AF/">
        生产经验—技术
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E7%94%9F%E4%BA%A7%E7%BB%8F%E9%AA%8C%E2%80%94%E7%83%AD%E7%82%B9%E9%97%AE%E9%A2%98/">
        生产经验—热点问题
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE/">
        实时数仓项目
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JavaSE/">
        JavaSE
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/Redis/">
        Redis
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/MySql/">
        MySql
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JVM/">
        JVM
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/JUC/">
        JUC
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E9%9D%A2%E8%AF%95%E8%AF%B4%E6%98%8E/">
        面试说明
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/LeetCode%E9%A2%98%E7%9B%AE%E7%B2%BE%E9%80%89/">
        LeetCode题目精选
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../%E5%85%B6%E4%BB%96/%E6%89%8B%E5%86%99HQL%E9%A2%98%E7%9B%AE%E7%BB%83%E4%B9%A0/">
        手写HQL题目练习
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_1">
    Spark Streaming第一次运行不丢失数据
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_2">
    Spark Streaming精准一次消费
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_3">
    Spark Streaming控制每秒消费数据的速度
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_4">
    Spark Streaming背压机制
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streamingstage">
    Spark Streaming一个stage耗时
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_5">
    Spark Streaming优雅关闭
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark-streaming_6">
    Spark Streaming默认分区个数
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sparkstreamingkafka">
    SparkStreaming有哪几种方式消费Kafka中的数据，它们之间的区别是什么？
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sparkstreaming">
    简述SparkStreaming窗口函数的原理（重点）
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_1">
    数据倾斜
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2">
    数据倾斜表现
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3">
    数据倾斜产生原因
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_4">
    解决数据倾斜思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_5">
    定位导致数据倾斜代码
  </a>
<nav aria-label="定位导致数据倾斜代码" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#task">
    某个task执行特别慢的情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#task_1">
    某个task莫名其妙内存溢出的情况
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key">
    查看导致数据倾斜的key分布情况
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#spark">
    Spark 数据倾斜的解决方案
  </a>
<nav aria-label="Spark 数据倾斜的解决方案" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#hive-etl">
    使用Hive ETL预处理数据
  </a>
<nav aria-label="使用Hive ETL预处理数据" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_6">
    适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_7">
    实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_8">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_9">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_10">
    方案实践经验
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_11">
    项目实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key_1">
    过滤少数导致倾斜的key
  </a>
<nav aria-label="过滤少数导致倾斜的key" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_12">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_13">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_14">
    方案实现原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_15">
    方案优缺点
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_16">
    方案实践经验
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shuffle">
    提高shuffle操作的并行度
  </a>
<nav aria-label="提高shuffle操作的并行度" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_17">
    方案适用场景
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_18">
    方案实现思路
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_19">
    方案实现原理
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/maomao199691/Python_Code.git/edit/master/docs/home/项目涉及技术/SparkStreaming.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"></path></svg>
</a>
<h1 id="spark-streaming">Spark Streaming</h1>
<h2 id="spark-streaming_1">Spark Streaming第一次运行不丢失数据</h2>
<p>  kafka参数 auto.offset.reset 参数设置成earliest 从最初始偏移量开始消费数据</p>
<h2 id="spark-streaming_2">Spark Streaming精准一次消费</h2>
<p>  （1）手动维护偏移量</p>
<p>  （2）处理完业务数据后，再进行提交偏移量操作</p>
<p>   极端情况下，如在提交偏移量时断网或停电会造成spark程序第二次启动时重复消费问题，所以在涉及到金额或精确性非常高的场景会使用事物保证精准一次消费</p>
<h2 id="spark-streaming_3">Spark Streaming控制每秒消费数据的速度</h2>
<p>  通过spark.streaming.kafka.maxRatePerPartition参数来设置Spark Streaming从kafka分区每秒拉取的条数</p>
<h2 id="spark-streaming_4">Spark Streaming背压机制</h2>
<p>  把spark.streaming.backpressure.enabled 参数设置为ture，开启背压机制后Spark
Streaming会根据延迟动态去kafka消费数据，上限由spark.streaming.kafka.maxRatePerPartition参数控制，所以两个参数一般会一起使用。</p>
<h2 id="spark-streamingstage">Spark Streaming一个stage耗时</h2>
<p>  Spark Streaming stage耗时由最慢的task决定，所以数据倾斜时某个task运行慢会导致整个Spark Streaming都运行非常慢。</p>
<h2 id="spark-streaming_5">Spark Streaming优雅关闭</h2>
<p>  把spark.streaming.stopGracefullyOnShutdown参数设置成ture，Spark会在JVM关闭时正常关闭StreamingContext，而不是立马关闭。</p>
<p>  Kill 命令：yarn application -kill     后面跟 applicationid</p>
<h2 id="spark-streaming_6">Spark Streaming默认分区个数</h2>
<p>  Spark Streaming默认分区个数与所对接的kafka topic分区个数一致，Spark Streaming里一般不会使用repartition算子增大分区，因为repartition会进行shuffle增加耗时。</p>
<h2 id="sparkstreamingkafka">SparkStreaming有哪几种方式消费Kafka中的数据，它们之间的区别是什么？</h2>
<p><strong>1）基于Receiver的方式</strong></p>
<p>  这种方式使用Receiver来获取数据。Receiver是使用Kafka的高层次Consumer API来实现的。receiver从Kafka中获取的数据都是存储在Spark Executor的内存中的（如果突然数据暴增，大量batch堆积，很容易出现内存溢出的问题），然后Spark Streaming启动的job会去处理那些数据。 </p>
<p>  然而，在默认的配置下，这种方式可能会因为底层的失败而丢失数据。如果要启用高可靠机制，让数据零丢失，就必须启用Spark Streaming的预写日志机制（Write Ahead Log，WAL）。该机制会同步地将接收到的Kafka数据写入分布式文件系统（比如HDFS）上的预写日志中。所以，即使底层节点出现了失败，也可以使用预写日志中的数据进行恢复。</p>
<p><strong>2）基于Direct的方式</strong></p>
<p>  这种新的不基于Receiver的直接方式，是在Spark 1.3中引入的，从而能够确保更加健壮的机制。替代掉使用Receiver来接收数据后，这种方式会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。 </p>
<p><strong>优点如下：</strong> </p>
<p>  <strong>（1）简化并行读取：</strong>如果要读取多个partition，不需要创建多个输入DStream然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在Kafka partition和RDD partition之间，有一个一对一的映射关系。 </p>
<p>  <strong>（2）高性能：</strong>如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有高可靠的机制，会对数据复制一份，而这里又会复制一份到WAL中。而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。 </p>
<p>  <strong>一次且仅一次的事务机制</strong>。</p>
<p><strong>3）对比：</strong></p>
<p>  基于receiver的方式，是使用Kafka的高阶API来在ZooKeeper中保存消费过的offset的。这是消费Kafka数据的传统方式。这种方式配合着WAL机制可以保证数据零丢失的高可靠性，但是却无法保证数据被处理一次且仅一次，可能会处理两次。因为Spark和ZooKeeper之间可能是不同步的。</p>
<p>  基于direct的方式，使用kafka的简单api，Spark Streaming自己就负责追踪消费的offset，并保存在checkpoint中。Spark自己一定是同步的，因此可以保证数据是消费一次且仅消费一次。</p>
<p>  在实际生产环境中大都用Direct方式</p>
<h2 id="sparkstreaming">简述SparkStreaming窗口函数的原理（重点）</h2>
<p>  窗口函数就是在原来定义的SparkStreaming计算批次大小的基础上再次进行封装，每次计算多个批次的数据，同时还需要传递一个滑动步长的参数，用来设置当次计算任务完成之后下一次从什么地方开始计算。</p>
<p>  图中time1就是SparkStreaming计算批次大小，虚线框以及实线大框就是窗口的大小，必须为批次的整数倍。虚线框到大实线框的距离（相隔多少批次），就是滑动步长。</p>
<h2 id="_1">数据倾斜</h2>
<p>  公司一：总用户量1000万，5台64G内存的服务器。</p>
<p>  公司二：总用户量10亿，1000台64G内存的服务器。</p>
<p>  （1）公司一的数据分析师在做join的时候发生了数据倾斜，会导致有几百万用户的相关数据集中到了一台服务器上，几百万的用户数据，说大也不大，正常字段量的数据的话64G还是能轻松处理掉的。</p>
<p>  （2）公司二的数据分析师在做join的时候也发生了数据倾斜，可能会有1个亿的用户相关数据集中到了一台机器上了（相信我，这很常见）。这时候一台机器就很难搞定了，最后会很难算出结果。</p>
<h2 id="_2">数据倾斜表现</h2>
<p><strong>1）hadoop 中的数据倾斜表现：</strong></p>
<ul>
<li>
<p>有一个多几个Reduce卡住，卡在99.99%，一直不能结束。</p>
</li>
<li>
<p>各种container报错OOM</p>
</li>
<li>
<p>异常的Reducer读写的数据量极大，至少远远超过其它正常的Reducer</p>
</li>
<li>
<p>伴随着数据倾斜，会出现任务被kill等各种诡异的表现。</p>
</li>
</ul>
<p><strong>2）hive 中数据倾斜</strong></p>
<p> 一般都发生在Sql中group by和join on上，而且和数据逻辑绑定比较深。</p>
<p><strong>3）Spark中的数据倾斜</strong></p>
<p> Spark中的数据倾斜，包括Spark Streaming和Spark Sql，表现主要有下面几种：</p>
<ul>
<li>
<p>Executor lost，OOM，Shuffle过程出错；</p>
</li>
<li>
<p>Driver OOM；</p>
</li>
<li>
<p>单个Executor执行时间特别久，整体任务卡在某个阶段不能结束；</p>
</li>
<li>
<p>正常运行的任务突然失败；</p>
</li>
</ul>
<h2 id="_3">数据倾斜产生原因</h2>
<p>  我们以Spark和Hive的使用场景为例。</p>
<p>  他们在做数据运算的时候会涉及到，count distinct、group by、join on等操作，这些都会触发Shuffle动作。一旦触发Shuffle，所有相同key的值就会被拉到一个或几个Reducer节点上，容易发生单点计算问题，导致数据倾斜。</p>
<p>  一般来说，数据倾斜原因有以下几方面：</p>
<p><center><strong>key分布不均匀</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/13/EKi3BCYVdvfwnLe.png"><img alt="trigger" src="https://s2.loli.net/2022/10/13/EKi3BCYVdvfwnLe.png" width="width"/></a></p>
<p><strong>2）建表时考虑不周</strong></p>
<p>  我们举一个例子，就说数据默认值的设计吧，假设我们有两张表：</p>
<p>  user（用户信息表）：userid，register_ip</p>
<p>  ip（IP表）：ip，register_user_cnt</p>
<p>  这可能是两个不同的人开发的数据表。如果我们的数据规范不太完善的话，会出现一种情况：</p>
<p>  user表中的register_ip字段，如果获取不到这个信息，我们默认为null；</p>
<p>  但是在ip表中，我们在统计这个值的时候，为了方便，我们把获取不到ip的用户，统一认为他们的ip为0。</p>
<p>  两边其实都没有错的，但是一旦我们做关联了，这个任务会在做关联的阶段，也就是sql的on的阶段卡死。</p>
<p><strong>3）业务数据激增</strong></p>
<p>  比如订单场景，我们在某一天在北京和上海两个城市多了强力的推广，结果可能是这两个城市的订单量增长了10000%，其余城市的数据量不变。</p>
<p>  然后我们要统计不同城市的订单情况，这样，一做group操作，可能直接就数据倾斜了。</p>
<h2 id="_4">解决数据倾斜思路</h2>
<p>  很多数据倾斜的问题，都可以用和平台无关的方式解决，比如更好的<strong>数据预处理</strong>，<strong>异常值的过滤</strong>等。因此，解决数据倾斜的重点在于对数据设计和业务的理解，这两个搞清楚了，数据倾斜就解决了大部分了。</p>
<p><strong>1）业务逻辑</strong></p>
<p>  我们从业务逻辑的层面上来优化数据倾斜，比如上面的两个城市做推广活动导致那两个城市数据量激增的例子，我们可以单独对这两个城市来做count，单独做时可用两次MR，第一次打散计算，第二次再最终聚合计算。完成后和其它城市做整合。</p>
<p><strong>2）程序层面</strong></p>
<p>  比如说在Hive中，经常遇到count(distinct)操作，这样会导致最终只有一个Reduce任务。</p>
<p>  我们可以先group by，再在外面包一层count，就可以了。比如计算按用户名去重后的总用户量：</p>
<p>  （1）优化前 只有一个reduce，先去重再count负担比较大：</p>
<p>    select name,count(distinct name)from user;</p>
<p>  （2）优化后</p>
<p>    // 设置该任务的每个job的reducer个数为3个。Hive默认-1，自动推断。</p>
<p>    set mapred.reduce.tasks=3;</p>
<p>    // 启动两个job，一个负责子查询(可以有多个reduce)，另一个负责count(1)：</p>
<p>    select count(1) from (select name from user group by name) tmp;</p>
<p><strong>3）调参方面</strong></p>
<p>  Hadoop和Spark都自带了很多的参数和机制来调节数据倾斜，合理利用它们就能解决大部分问题。</p>
<p><strong>4）从业务和数据上解决数据倾斜</strong></p>
<p>  很多数据倾斜都是在数据的使用上造成的。我们举几个场景，并分别给出它们的解决方案。</p>
<ul>
<li>
<p>有损的方法：找到异常数据，比如ip为0的数据，过滤掉</p>
</li>
<li>
<p>无损的方法：对分布不均匀的数据，单独计算</p>
</li>
<li>
<p>先对key做一层hash，先将数据随机打散让它的并行度变大，再汇集</p>
</li>
<li>
<p>数据预处理</p>
</li>
</ul>
<h2 id="_5">定位导致数据倾斜代码</h2>
<p>  Spark数据倾斜只会发生在shuffle过程中。</p>
<p>  这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。</p>
<p>  出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。</p>
<h3 id="task">某个task执行特别慢的情况</h3>
<p>  首先要看的，就是数据倾斜发生在第几个stage中：</p>
<p>  如果是用yarn-client模式提交，那么在提交的机器本地是直接可以看到log，可以在log中找到当前运行到了第几个stage；</p>
<p>  如果是用yarn-cluster模式提交，则可以通过Spark Web UI来查看当前运行到了第几个stage。</p>
<p>  此外，无论是使用yarn-client模式还是yarn-cluster模式，我们都可以在Spark Web UI上深入看一下当前这个stage各个task分配的数据量，从而进一步确定是不是task分配的数据不均匀导致了数据倾斜。</p>
<p>  看task运行时间和数据量</p>
<p>  task运行时间</p>
<p>  比如下图中，倒数第三列显示了每个task的运行时间。明显可以看到，有的task运行特别快，只需要几秒钟就可以运行完；而有的task运行特别慢，需要几分钟才能运行完，此时单从运行时间上看就已经能够确定发生数据倾斜了。</p>
<p>  task数据量</p>
<p>  此外，倒数第一列显示了每个task处理的数据量，明显可以看到，运行时间特别短的task只需要处理几百KB的数据即可，而运行时间特别长的task需要处理几千KB的数据，处理的数据量差了10倍。此时更加能够确定是发生了数据倾斜。</p>
<p>  推断倾斜代码</p>
<p>  知道数据倾斜发生在哪一个stage之后，接着我们就需要根据stage划分原理，推算出来发生倾斜的那个stage对应代码中的哪一部分，这部分代码中肯定会有一个shuffle类算子。</p>
<p>  精准推算stage与代码的对应关系，需要对Spark的源码有深入的理解，这里我们可以介绍一个相对简单实用的推算方法：只要看到Spark代码中出现了一个shuffle类算子或者是Spark SQL的SQL语句中出现了会导致shuffle的语句（比如group by语句），那么就可以判定，以那个地方为界限划分出了前后两个stage。</p>
<p>  这里我们就以如下单词计数来举例。</p>
<p>  val conf = new SparkConf()val sc = new SparkContext(conf)val lines = sc.textFile("hdfs://...")val words = lines.flatMap(<em>.split(" "))val pairs = words.map((</em>, 1))val wordCounts = pairs.reduceByKey(<em> + </em>)wordCounts.collect().foreach(println(_))</p>
<p>  在整个代码中只有一个reduceByKey是会发生shuffle的算子，也就是说这个算子为界限划分出了前后两个stage：</p>
<p>  stage0，主要是执行从textFile到map操作，以及shuffle write操作（对pairs RDD中的数据进行分区操作，每个task处理的数据中，相同的key会写入同一个磁盘文件内）。</p>
<p>  stage1，主要是执行从reduceByKey到collect操作，以及stage1的各个task一开始运行，就会首先执行shuffle read操作（会从stage0的各个task所在节点拉取属于自己处理的那些key，然后对同一个key进行全局性的聚合或join等操作，在这里就是对key的value值进行累加）</p>
<p>  stage1在执行完reduceByKey算子之后，就计算出了最终的wordCounts RDD，然后会执行collect算子，将所有数据拉取到Driver上，供我们遍历和打印输出。</p>
<p>  123456789</p>
<p>  通过对单词计数程序的分析，希望能够让大家了解最基本的stage划分的原理，以及stage划分后shuffle操作是如何在两个stage的边界处执行的。然后我们就知道如何快速定位出发生数据倾斜的stage对应代码的哪一个部分了。</p>
<p>  比如我们在Spark Web UI或者本地log中发现，stage1的某几个task执行得特别慢，判定stage1出现了数据倾斜，那么就可以回到代码中，定位出stage1主要包括了reduceByKey这个shuffle类算子，此时基本就可以确定是是该算子导致了数据倾斜问题。</p>
<p>  此时，如果某个单词出现了100万次，其他单词才出现10次，那么stage1的某个task就要处理100万数据，整个stage的速度就会被这个task拖慢。</p>
<h3 id="task_1">某个task莫名其妙内存溢出的情况</h3>
<p>  这种情况下去定位出问题的代码就比较容易了。我们建议直接看yarn-client模式下本地log的异常栈，或者是通过YARN查看yarn-cluster模式下的log中的异常栈。一般来说，通过异常栈信息就可以定位到你的代码中哪一行发生了内存溢出。然后在那行代码附近找找，一般也会有shuffle类算子，此时很可能就是这个算子导致了数据倾斜。</p>
<p>  但是大家要注意的是，不能单纯靠偶然的内存溢出就判定发生了数据倾斜。因为自己编写的代码的bug，以及偶然出现的数据异常，也可能会导致内存溢出。因此还是要按照上面所讲的方法，通过Spark Web UI查看报错的那个stage的各个task的运行时间以及分配的数据量，才能确定是否是由于数据倾斜才导致了这次内存溢出。</p>
<h2 id="key">查看导致数据倾斜的key分布情况</h2>
<p>  先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印样本数据中各个key的出现次数。</p>
<p>  val sampledPairs = pairs.sample(false, 0.1)</p>
<p>  val sampledWordCounts = sampledPairs.countByKey()</p>
<p>  sampledWordCounts.foreach(println(_))</p>
<h2 id="spark">Spark 数据倾斜的解决方案</h2>
<h3 id="hive-etl">使用Hive ETL预处理数据</h3>
<h4 id="_6">适用场景</h4>
<p>  导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。</p>
<h4 id="_7">实现思路</h4>
<p>  此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。</p>
<h4 id="_8">方案实现原理</h4>
<p>  这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。</p>
<h4 id="_9">方案优缺点</h4>
<p>  优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</p>
<p>  缺点：治标不治本，Hive ETL中还是会发生数据倾斜。</p>
<h4 id="_10">方案实践经验</h4>
<p>  在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</p>
<h4 id="_11">项目实践经验</h4>
<p>  在美团·点评的交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。</p>
<h3 id="key_1">过滤少数导致倾斜的key</h3>
<h4 id="_12">方案适用场景</h4>
<p>  如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</p>
<h4 id="_13">方案实现思路</h4>
<p>  如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。</p>
<p>  比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。</p>
<p>  如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。</p>
<h4 id="_14">方案实现原理</h4>
<p>  将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。</p>
<h4 id="_15">方案优缺点</h4>
<p>  优点：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</p>
<p>  缺点：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。</p>
<h4 id="_16">方案实践经验</h4>
<p>  在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</p>
<h3 id="shuffle">提高shuffle操作的并行度</h3>
<h4 id="_17">方案适用场景</h4>
<p>  如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。</p>
<h4 id="_18">方案实现思路</h4>
<p>  在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，默认是200，对于很多场景来说都有点过小。</p>
<h4 id="_19">方案实现原理</h4>
<p>  增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。</p>
<p>  而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。</p>
<p><center><strong>提高shuffle操作的并行度-方案实现原理</strong></center></p>
<p><a class="glightbox" data-desc-position="bottom" data-description="" data-height="auto" data-title="" data-width="100%" href="https://s2.loli.net/2022/10/14/WVyNdCvUgOswzxH.png"><img alt="trigger" src="https://s2.loli.net/2022/10/14/WVyNdCvUgOswzxH.png" width="width"/></a></p>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: Spark Core&amp;SQL" class="md-footer__link md-footer__link--prev" href="../SparkCore%26SQL/" rel="prev">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Previous
              </span>
              Spark Core&amp;SQL
            </div>
</div>
</a>
<a aria-label="Next: Flink" class="md-footer__link md-footer__link--next" href="../Flink/" rel="next">
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Next
              </span>
              Flink
            </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2016 - 2020 Martin Donath
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://twitter.com/squidfunk" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
<script src="../../../assets/javascripts/bundle.078830c0.min.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom"});})</script></body>
</html>